{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TOJ91wNChUFiUDBvXAxYSbQSpilKuPvl","timestamp":1710253144320}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qVsU04EWCQzn"},"source":["#**Autoencoders**\n","\n","In the previous step we described how methods such as Neural Networks or linear regresion could be used to make predictions. We also discussed in previous steps how Principal Components could be used to both reduce dimensionality and help remove noise.\n","Autoencoders are a form of unsupervised technique which use neural networks to help reduce dimensionality or remove noise by compressing our input data through a hidden layer back to an orginal represention of the input layer. Figure 1 shows how the network compresses the data before recreating it in the output layer.\n","\n","<img src=\"https://www.computing.dcu.ie/~amccarren/mcm_images/autoencoder.png\"/>\n","\n","Figure 1 [Source](https://www.jeremyjordan.me/autoencoders/)\n","\n","We examine this process a little more by looking at Figure 2 where we see there is an \"Encoder\" used to create \"h\" the latent representation. The latent representation can then be used as a decompressed or dimensionally reduced dataset.\n","\n","<img src=\"https://www.computing.dcu.ie/~amccarren/mcm_images/Autoencoder_2.png\"/>\n","\n","Figure 2 (source: [Towards Data Science](https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f))\n","\n","Autoencoders are only useful when there are relationships between the input variables, as mathematically it is difficult to compress the features without substanial loss of information, if there was no correlation between the variables. However, if there is a relationship then the structure can be learned, and we can effectively compress our data into a hidden layer. The outcome variable is a transformed version of the hidden nodes. Thus the output variables can be considered to be denoised.\n","\n","Now we have outlined that Autoencoders can be used for dimensionality reduction as we will be creating a lower number of latent variables than the number of original input variables. This is similar to PCA. So what are there the differences?\n","\n","* PCA is a linear transformation of the data and assumes the new latent variables are linear combination of the original variables.\n","\n","* PCA features are not linearly correlated but Autoencoders might have correlations\n","\n","* PCA is less computationally intensive than Autoencoders.\n","\n","* A single layered autoencoder with a linear activation function is very similar to PCA.\n","\n","* Autoencoders may require regularisation as they are prone to overfitting.\n","\n","In the code below we build an autoencoder using Keras. The dataset is the Minst dataset which composes of 60000 images of numbers. Each picture has 28x28 (784) pixels. We will flatten each picture into a single vector and then use these vectors as training data to our Neural Network.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8i3KBLm2f_k5"},"source":["In order to understand the difference between the various [optimizers](http://tflearn.org/optimizers/) have a look at this artcile from [Toward Science](https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b). It should give you a feel for how they work. You can now see that we have an Autoencoder framework built to process all our images.\n","\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","from keras.utils import plot_model\n","from keras import optimizers\n","from keras import regularizers\n","from keras.optimizers import RMSprop\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","img_rows, img_cols = 28, 28\n","\n","# Reshape the images to add the channel dimension. The channel dimension indicates how many color layers each pixel has.\n","# MNIST has 1 channel (grayscale). While, a normal color photo has 3 channels (R, G, B).\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","\n","# Converting the pixel values in images from integers (0–255) to floating-point numbers (decimal values).\n","# By default, MNIST images are stored as unsigned 8-bit integers (uint8), meaning each pixel is an integer between 0 and 255.\n","# Neural networks work better with floating-point data, so we convert them to float32 type.\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","# Normalizing the data, which helps the neural network train faster and more stably.\n","# Large unscaled inputs (like 0–255) can make gradient-based optimization harder.\n","x_train /= 255\n","x_test /= 255\n","\n","\n","# Flattenning the images manually\n","x_train = np.array(x_train)\n","x_train = x_train.reshape(60000,784)\n","\n","# Defining the model’s structure\n","model = Sequential() # Creates an empty neural network using Keras’s Sequential API, which lets you stack layers one after another, similar to a pipeline.\n","model.add(Dense(128,activation='relu',input_dim=784)) # This layer compresses the 784-pixel input down to 128 features. It’s the encoder part of the autoencoder.\n","model.add(Dense(128,activation='relu',input_dim=128)) # This layer refines the representation learned by the first layer.\n","model.add(Dense(784,activation='relu')) # This layer has 784 output neurons — one for each pixel of the input image to reconstruct the original input image. So, this is the decoder part of the autoencoder.\n","\n","# Preparing the model for training by setting up the loss function, optimizer, and metrics.\n","model.compile(loss='mean_squared_error', optimizer='RMSprop', metrics = ['accuracy'])\n","# Showing the model's structure\n","plot_model(model, to_file='model_plot.png',  show_layer_names=True)\n"],"metadata":{"id":"DN5Vvl34E2KX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qIp_RWpih_qS"},"source":["We now have a our framework which is shown above and we can now run our data through it using the model.fit method. We will save the model to our local google drive. This is worth doing regularly as you may have to start your analysis again as third party platforms like Google Colab will shut you out after a specified time."]},{"cell_type":"code","metadata":{"id":"n7IWYLpvrmzK"},"source":["history=model.fit(x_train,x_train,verbose=1,epochs=2,batch_size=256)\n","model.save('/content/auto_en.keras')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22btgwm-tMcB"},"source":["print(history.history['loss'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gBf0-lBHjB1-"},"source":["**In this code snipet we are trying to extract the data from the hidden layer (128). We could use this data as a reduced dataset for further analysis.**"]},{"cell_type":"code","metadata":{"id":"904v7dokBjRN"},"source":["from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.layers import Input\n","\n","# Load the model\n","seq_model = load_model('/content/auto_en.keras')\n","\n","\n","inputs = Input(shape=(784,))\n","x = seq_model.layers[0](inputs)\n","x = seq_model.layers[1](x)\n","encoded_model = Model(inputs, x)\n","\n","x_train_encoded = encoded_model.predict(x_train)\n","print(\"Encoded data shape:\", x_train_encoded.shape)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhskY0AUqh8B"},"source":["from keras.models import load_model\n","import cv2\n","import matplotlib.pyplot as plt\n","#from google.colab.patches import cv2_imshow\n","model = load_model('/content/auto_en.keras')\n","\n","test = x_train[1].reshape(1,784)\n","y_test = model.predict(test)\n","\n","inp_img = []\n","temp = []\n","for i in range(len(test[0])):\n","    if((i+1)%28 == 0):\n","        temp.append(test[0][i])\n","        inp_img.append(temp)\n","        temp = []\n","    else:\n","        temp.append(test[0][i])\n","out_img = []\n","temp = []\n","for i in range(len(y_test[0])):\n","    if((i+1)%28 == 0):\n","        temp.append(y_test[0][i])\n","        out_img.append(temp)\n","        temp = []\n","    else:\n","        temp.append(y_test[0][i])\n","\n","inp_img = np.array(inp_img)\n","out_img = np.array(out_img)\n","#plt.imshow('Test Image',inp_img)\n","plt.title('Input Image')\n","\n","plt.imshow(cv2.cvtColor(inp_img, cv2.COLOR_BGR2RGB))\n","plt.show()\n","plt.title('Output Image')\n","\n","plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n","plt.show()\n","#cv2_imshow(inp_img)\n","#cv2.imshow('Output Image',out_img)\n","#cv2.waitKey(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3A5N10xmkY3"},"source":["Hopefully by now you will have got the idea of an Autoencoder. Now I would like you to try a few things before we move on and they are as follows:\n","\n","* Print out a larger number of pictures.\n","\n","* Run a a number of epochs  and print a graph of the Epoch number against the Loss or MSE. You may find this [code](https://keras.io/visualization/) useful.\n","\n","* Do this analysis for the Boston housing data. Try and use the hidden layer as input to both a regression and Neural Network to predict housing prices.\n","\n"]},{"cell_type":"code","metadata":{"id":"Ald5577dnVt-"},"source":["import matplotlib.pyplot as plt\n","\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]}]}