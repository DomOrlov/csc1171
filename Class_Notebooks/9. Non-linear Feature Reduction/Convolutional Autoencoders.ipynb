{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9emFkYJlL8o"
   },
   "source": [
    "#**Convolutional Autoencoders**\n",
    "\n",
    "In MOOC 4 we will talk about image preprocessing and how we can use terms known as convolutions, max pooling and upsampling to help us preprocess an image. Some of you may be familiar with these terms so this step will be relatively easy to extend from the regular autoencoder. If you are not familar with them then go to this [link](https://pathmind.com/wiki/convolutional-network).\n",
    "\n",
    "In step 3.3.4 we outlined how an autoencoder works. This process is very similar for convolutional autoencoders. Figure 1 shows the structure of  CNN autoencoder. Convolutional Autoencoders can be used to reduce the levels of noise found in images and can be a very useful preprocessing step.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://www.computing.dcu.ie/~amccarren/mcm_images/convolutional_autoencoder.png\" class=\"center\"/>\n",
    "\n",
    "Figure 1: CNN Autoencoder (Xifeng Guo, ResearchGate)\n",
    "\n",
    "As you can see from Figure 1, it is very similar to regular autoencoder, with the exception that it has multiple dimensions. I won't be going into to much detail here as we you will learn all about CNN's in Machine learning with Prof Tomas Ward. However, I want to run through an example of how a convolutional Autoencoders works using a simple example.\n",
    "\n",
    "Now we will use the Mnist dataset from the keras dataset library, as we did in previous examples, but this time we will add some noise to each image.\n",
    "\n",
    "\n",
    "Make sure you set tensorflow to version 2.x and open a folder the you want to work in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 14070,
     "status": "ok",
     "timestamp": 1763138932426,
     "user": {
      "displayName": "Maryam Basereh",
      "userId": "17916650843126787012"
     },
     "user_tz": 0
    },
    "id": "cQa9w37LmkG7"
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7H1DmpJYyG3"
   },
   "source": [
    "The next code snippet imports the data from keras and seperates into a trianing a learning datasets. Following the data importation we now add some noise to the data which creates \"fuzzy\" images. You can just make out the profile of the numbers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYw2nntCsqiH"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x_train1 = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test1 = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data\n",
    "print(x_train1[0].shape)\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train1 + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train1.shape)\n",
    "x_test_noisy = x_test1 + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test1.shape)\n",
    "\n",
    "x_train1= np.clip(x_train_noisy, 0., 1.)\n",
    "x_test1 = np.clip(x_test_noisy, 0., 1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wY7Km5ZhwDAJ"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34EPirPhwU3o"
   },
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WidtmQ8FZv7V"
   },
   "source": [
    "Lets look at the noisy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9K1DfZ3nX9B5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_train[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EgYHKG2aij1"
   },
   "source": [
    "The following code snippet sets up the model in Keras. In this code there are 3 convolutional layers decompressing the image and then 3 layers bringing them back to the output layer. A really nice explaination of the process behind a CNN is given by [Adrian Rosebrock (pyimagesearch)](https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/). Adrian explains each of the parameters that go into the layers and explains in a very simple way how each layer has a kernal applied to it. Kernals will reduce the layers as you apply more convolutions, effectively reducing the data from layer to layer. This will also happen with a term called maxpooling, and it effectively helps us denoise our data.\n",
    "\n",
    "Now the object of our excercise here is to see if we can remove some of the noise from the image and get clearer pictures. In this example maxpooling effectively shrinks our matrix while the upsampling trys to rebuild it. You will now note that the convolutions with the exception of one layer, all have \"padding=same\". That means the kernals will not reduce the matrix in this case.\n",
    "\n",
    "This is a bit light but try it out and play with the code and see what happens. Have a look at the calculations at each level (in comments beside the code). You will notice that we have one layer without any padding. When this happens the kernal (3,3) will reduce the dimension by 2.\n",
    "\n",
    "It is very important that you understand this as both applying a kernal and maxpooling will reduce the dimension of the input matrix.\n",
    "This [site](https://icecreamlabs.com/2018/08/19/3x3-convolution-filters%E2%80%8A-%E2%80%8Aa-popular-choice/) gives a nice visualisation of how a kernal works.\n",
    "\n",
    "\n",
    "Take a look at the network structure. When you experiment with it, make sure the your output matrix dimensions are the same as the input dimensions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08k9xjstk1pW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "\n",
    "if K.image_data_format() == 'channels_first' :\n",
    "  input_shape = (1, 28, 28)\n",
    "  x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "  x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "else:\n",
    "  input_shape = (28, 28, 1)\n",
    "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "input_img = (28, 28, 1)\n",
    "print(input_shape)\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same',input_shape=input_img)) #image size 28x28\n",
    "model.add(MaxPooling2D((2, 2))) #image size 14x14 max pooling reduces dimesnion by half\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same')) #image size 14x14\n",
    "model.add(MaxPooling2D((2, 2))) #image size 7x7\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same')) #image size 7x7\n",
    "model.add( MaxPooling2D((2, 2), padding='same')) #max pooling rounds up 4x4 if padding =same\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same')) # image size 4x4\n",
    "model.add(UpSampling2D((2, 2))) # image doubled to 8x8\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2))) # image size 8x8\n",
    "model.add(Conv2D(32, (3, 3), activation='relu')) # 14x14 image reduces by 2 for both rows as kernal will reduces it without padding =same\n",
    "model.add(UpSampling2D((2, 2))) #28x28 image doubles\n",
    "model.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same')) # bringing  the filters back to 1\n",
    "\n",
    "#'mean_squared_error','binary_crossentropy'\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "#              optimizer=tf.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0),\n",
    "\n",
    "              metrics = ['accuracy'])\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rcWfobn4A5p"
   },
   "source": [
    "Now we are going to fit the model to the data. This is exactly the same as the regular autoencoder.  We are going to use 50 epochs and our batch size is 128. Play with these and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "yqRkjbwqtueH",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, x_train,verbose=1,epochs=50, batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jvoasqSuP92"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(x_test)\n",
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display noisey data\n",
    "    ax = plt.subplot(3, n, i+n)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + (2*n))\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCWsUkvN7OSg"
   },
   "source": [
    "Finally, We have 3 rows of pictures. The first is the orignal numbers. The second is the noisey numbers and the third are the denoised number.You can see we have managed to re-create the images without most of the noise. They are not perfect but they are a vast improvement from the nosiey images.\n",
    "\n",
    "I would like you to experiment with the structure of the autoencoder. Try and reduce the kernal size to a 2x2. Can you get the system to work? Don't forget to leave your comments on the comments board.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
