{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eHVcBzk0mh0S"},"source":["#**DBSCAN**\n","\n","DBSCAN differs from the K-Means and K-Mediods algoritm in so far as it a density based algorithm as opposed to a partion approach. The DBSCAN algorithm views clusters as areas of high density separated by areas of low density and tries to avoid including \"outliers\" in clusters. A really nice explaination of the algorithm can be found on the [Scikit learn site](https://scikit-learn.org/stable/modules/clustering.html#dbscan).\n","\n","The following definitions are useful and will help you understand the algorithm.\n","\n",">* Density is defined as the number of points within a specified radious,\n","\n",">* A point is a core point if it has  more  than a specified number of points (MinPts) within Eps. These are points that are at the interior of a cluster.\n","\n",">* A border point has  fewer  than MinPts within Eps,  but in the neighborhood of a core point\n","\n",">* A noise  point is any  point that is not a core point or a border point.\n","\n","![](https://www.computing.dcu.ie/~amccarren/mcm_images/dbscan_2.png)\n","Figure 1: DBSCAN implementation\n","\n",">* Label all points as core, border, or noise points.\n",">* Eliminate noise points.\n",">* Put an edge between all core points that are within $\\epsilon$ of each other.\n",">* Make each group of connected core points into a separate cluster.\n",">* Assign each border point to one of the clusters of its associated core points.\n","\n","\n","**Advantages**\n",">* Can discover arbitrarily shaped clusters\n",">* Can find a cluster completely surronded by different clusters\n",">* Robust toward outlier detection\n",">* Insentitive o the ordering of the points in the database\n","\n","**Disadvantages**\n",">* DBSCAN Does not work well when dealing with clusters of varying densities.\n","\n",">* While DBSCAN is great at separating high density clusters from low density clusters, DBSCAN struggles with clusters of similar density.\n","\n",">* Struggles with high dimensionality data.\n","\n","\n","There are other density based approaches such as OPTICS, Ankerst et al (SIGMOD'99) and DENCLUE, Hinneburg & Keim (KDD'98).\n","We will now implement an example which comes fro scikit learn.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"S18bjDm16a6g"},"source":["As usual import the relevant library."]},{"cell_type":"code","metadata":{"id":"7DtXlVfr525s","executionInfo":{"status":"ok","timestamp":1763281126709,"user_tz":0,"elapsed":4907,"user":{"displayName":"Maryam Basereh","userId":"17916650843126787012"}}},"source":["import numpy as np\n","\n","from sklearn.cluster import DBSCAN\n","from sklearn import metrics\n","from sklearn.datasets import make_blobs\n","from sklearn.preprocessing import StandardScaler\n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"siT6Zqym6gkd"},"source":["The next code snipet creates a data blob from sckit learn, and then standardizes the data."]},{"cell_type":"code","metadata":{"id":"nBF_BPN458bR"},"source":["# #############################################################################\n","# Generate sample data\n","centers = [[1, 1], [-1, -1], [1, -1]]\n","X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n","                            random_state=0)\n","\n","X = StandardScaler().fit_transform(X)\n","print(X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C-kF2OGy9560"},"source":["We now implement the DBSCAN algorithm. Note the values of \"eps\" and \"min_samples\". These correspond to the maximum radius of the neighbourhood and the minimum number of points in an \"eps\" neighbourhood of that point. If you play with these you should see the number of clusters generated change."]},{"cell_type":"code","metadata":{"id":"DYv6E6kFkeUB"},"source":["\n","\n","\n","# #############################################################################\n","# Compute DBSCAN\n","db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n","core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n","core_samples_mask[db.core_sample_indices_] = True\n","labels = db.labels_\n","\n","# Number of clusters in labels, ignoring noise if present.\n","n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n","n_noise_ = list(labels).count(-1)\n","\n","print('Estimated number of clusters: %d' % n_clusters_)\n","print('Estimated number of noise points: %d' % n_noise_)\n","print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n","print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n","print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n","print(\"Adjusted Rand Index: %0.3f\"\n","      % metrics.adjusted_rand_score(labels_true, labels))\n","print(\"Adjusted Mutual Information: %0.3f\"\n","      % metrics.adjusted_mutual_info_score(labels_true, labels))\n","print(\"Silhouette Coefficient: %0.3f\"\n","      % metrics.silhouette_score(X, labels))\n","\n","# #############################################################################\n","# Plot result\n","import matplotlib.pyplot as plt\n","\n","# Black removed and is used for noise instead.\n","unique_labels = set(labels)\n","colors = [plt.cm.Spectral(each)\n","          for each in np.linspace(0, 1, len(unique_labels))]\n","for k, col in zip(unique_labels, colors):\n","    if k == -1:\n","        # Black used for noise.\n","        col = [0, 0, 0, 1]\n","\n","    class_member_mask = (labels == k)\n","\n","    xy = X[class_member_mask & core_samples_mask]\n","    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n","             markeredgecolor='k', markersize=14)\n","\n","    xy = X[class_member_mask & ~core_samples_mask]\n","    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n","             markeredgecolor='k', markersize=6)\n","\n","plt.title('Estimated number of clusters: %d' % n_clusters_)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsaXXzxuCTP2"},"source":["We can see from the output that the algorithm works pretty well.How sensitive is the algorithm to changes in $\\epsilon$ and the minimum number of points?\n","\n","As usual leave your thoughts on the comments board.\n"]}]}