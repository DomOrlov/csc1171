{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz1IKsqqECuI"
   },
   "source": [
    "# **Logistic Regression**\n",
    "\n",
    "We have now recapped on inferential statistics, Analysis of Variance and Linear regression. But students always want to know how do I model categorical variables, or how do I classify a piece of data. Logistic regression is one of the simplest classifiers and we will give a quick introduction to it in this section. However, logistic regression comes from the Generalised Linear model family of models and we will examine it in much more detail in the later.\n",
    "\n",
    "<br/>\n",
    "\n",
    "The objective of Logistic Regression is to model binary outcomes. In linear regression we modelled continous outcomes such as sales or prices with independent variables. Logistic regression is used to model the probability of a categorical outcome/dependent variable. This variable will have 2 options which are either a 1 or a 0, and the logistic regression model will attempt to predict P(Y=1) as a function of X.\n",
    "\n",
    "**The Logistic Regression Assumptions**\n",
    "\n",
    "* Binary logistic regression requires the dependent variable to be binary.\n",
    "\n",
    "* For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome.\n",
    "\n",
    "* Only the meaningful variables should be included.\n",
    "The independent variables should be independent of each other. That is, the model should have little or no multicollinearity. Multicollinearity occurs when a linear combination of one or more independent variables is collinear with another variable. This charactersitic has a habit of inflating the variance of the parameter estimate in question and can wrongly accept the null hypothesis that the variable is not significantly different from zero.\n",
    "\n",
    "* The independent variables are linearly related to the log odds.\n",
    "* Logistic regression requires quite large sample sizes.\n",
    "\n",
    "Keeping the above assumptions in mind, letâ€™s look at a dataset. The dataset is the success rate of people applying for a specific position. Each candidates Graduate Management Admission Test score, GPA score and work expreience were also recorded. The aim of this analyis is to determine which variables should be used when making a decision to accept or reject a candidate.\n",
    "\n",
    "We will read the data into a dataframe called candidates and this is outlined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJs6JyX1FF9Z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.stats.stattools as st\n",
    "import statsmodels.stats.api as sms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1726433447387,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "Tebi14FlEF2f",
    "outputId": "46033eb8-f678-4d1d-933d-f72210dbb8dd"
   },
   "outputs": [],
   "source": [
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,1,1,1,1,0,1,1,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "\n",
    "\n",
    "df.describe()\n",
    "#from google.colab import files\n",
    "#df.to_csv('candidates.csv')\n",
    "#files.download('candidates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2UHFZk-EICo"
   },
   "source": [
    "We have now imported the data and printed a summary analysis of the data using the Pandas \"describe\" method. By doing this we can easily see that the problems is well balanced between accept and reject for the admitted variable. This is very convenient, as normally this would not be the case. When problems are imbalanced we should really deal with this as part of the problem.\n",
    "\n",
    "The next thing you will have noticed is the mean response for the 3 independent varibles which are as follows:\n",
    ">gmat |\tgpa |\twork_experience\n",
    ">--- | --- | ---\n",
    ">654.00\t| 3.095\t| 3.425\n",
    "\n",
    "We can see that the gpa and work_experience variables are of a similar scale but gmat is a factor of 100 greater. Many people when starting out in their analytics journey feel the need to standardise their data as a preprocessing step. This is not necessary if you are dealing with a linear model, as we are not using complex optimisation routines. We will look at differing methods to standardise data in the next MOOC but **in the case of logistic or linear regression there is absolutely no need to standardise your independent variables**. In fact if you do this you will be actually reduce the volume of information from your model, thus reducing the models predictive power.\n",
    "\n",
    "You may want to center your independent variables as this may improve the interpretation of the intercept. When you center a variable the intercept becomes the mean of the Y variable at the value you centered on, but importantly the slopes/paremeter estimates will not change. But for this logistic model we will find that model will fail as well get \"perfect seperation\". This is usually caused by over specification of the model (To many variables). Try it out and see what happens. See if you can get results using 2 variables and no intercept. What do you notice about the p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1726433455680,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "-P4huQQoEOoK",
    "outputId": "1528bf51-094c-4c12-a5f8-3f4102455c2d"
   },
   "outputs": [],
   "source": [
    "#df['gmat_t']=(df['gmat']-df['gmat'].min())/(df['gmat'].max()-df['gmat'].min())\n",
    "#print(df['gmat_t'])\n",
    "#df['gpa']=df['gpa']-df['gpa'].mean()\n",
    "#df['work_experience']=df['work_experience']-df['work_experience'].mean()\n",
    "#df['gmat']=df['gmat']-df['gmat'].mean()\n",
    "sns.countplot(x='admitted',data=df,palette='hls')\n",
    "plt.show()\n",
    "plt.savefig('count_plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIwkz98VER3g"
   },
   "source": [
    "We see from the above histogram that the \"admitted\" variable is well balanced. Generally, we should really complete a number of plots and a correlation analysis to examine the relationship between variables. If 2 variables are highly correlated then it is appropriate to drop one of these variables from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1726433464497,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "68-p5IQ0EUXp",
    "outputId": "a76749f0-c5dc-4224-a13e-eda73c75b644"
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "%matplotlib inline\n",
    "df.plot.scatter(x='gpa', y='work_experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1726433470580,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "dXsCh7lyEXLA",
    "outputId": "1e479d5f-8528-4a0d-b763-10086f0e9679"
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "%matplotlib inline\n",
    "df.plot.scatter(x='gpa', y='gmat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1726433476363,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "wmjzZVxKEZ0h",
    "outputId": "c212546e-0bbb-457c-cbaf-2f6f2ccb61d8"
   },
   "outputs": [],
   "source": [
    "corr = df[['gpa','work_experience','gmat']].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAHssazyEdSJ"
   },
   "source": [
    "# The 3 independent variables do appear to have some correlation between them, but we cannot be sure how this will affect our model. In order to assess this we should really examine the multi-collinearity between all the independent variables. The code below shows how we can assess multi-collinearity using a term known as the \"variance inflation factor\" or VIF. VIF is calculated by regressing a independent variable against all the other variables and using the following formula:\n",
    "$$ V.I.F. = 1 / (1 - R^2). $$\n",
    "\n",
    "If your VIF factor is >10 then you really need to consider dropping variables from your model. In the example below we can see that the following equations give the VIF calculated from the code:\n",
    "\n",
    "<br/>\n",
    "\n",
    "$gmat=\\alpha{} + \\beta{}_1.gpa +\\beta{}_2.workexperience$ gives a VIF of 1.88\n",
    "\n",
    "$gpa=\\alpha{} + \\beta{}_1.gmat +\\beta{}_2.workexperience$ gives a VIF of 1.54\n",
    "\n",
    "$workexperience=\\alpha{} + \\beta{}_1.gpa +\\beta{}_2.gmat$ gives a VIF of 1.47\n",
    "\n",
    "<br/>\n",
    "\n",
    "While gmat and gpa only had a correlation coefficent of 0.56 which is not excessively high we see that the there is little multi-collinearity between the variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1726433482195,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "H-vZUC5YEgPB",
    "outputId": "81879f8d-c446-4fa1-c2ee-99203e5896cd"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "from statsmodels.api import add_constant\n",
    "X=df[['gpa','work_experience','gmat']]\n",
    "X = add_constant(X)\n",
    "y=df['admitted']\n",
    "vif = [variance_inflation_factor(X.to_numpy(), i) for i in range(X.to_numpy().shape[1])]\n",
    "\n",
    "print(vif[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EEWz7YL9Xd6"
   },
   "source": [
    "Now we will run a number of logistic regression models and see which ones make most sence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1726433487416,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "7SrwAAYoEi0J",
    "outputId": "9136f600-a22d-4efc-ea06-90535e0b9745"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.discrete.discrete_model as sml\n",
    "X=df[['gpa','gmat','work_experience']]\n",
    "#X=df[['gpa','work_experience']]\n",
    "#X = add_constant(X)\n",
    "#X=df[['work_experience']]\n",
    "logit = sml.Logit(y, X).fit()\n",
    "print(logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TggbLxT4Em_K"
   },
   "source": [
    "*   Pseudo R-squ. is similar to the $R^2$ in linear regression\n",
    "*   LLR p-value: tells if the model is significantly better than a null model\n",
    "* The confusion matrix tells which categories are more likely to be predicted correctly and incorectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSK7ZOnCEq14"
   },
   "source": [
    "Now by interchanging GPA, GMAT and the intercept we get differing values for the Rseudo $R^2$ or none at all as the model fails. In order to determine which model is most appropriate we would take the  Pseudo $R^2$, the pvalues and the LLR pvalue into account. We would then examine the Accuarcy, F1-score and the Area under the curve. Sometimes it is a tough call but in this situation we would probably use the gmat, gpa and work_experience variables with no intercept, as they give the  highest $R^2$ and LLT P-value is highly significant. However, the coeffficent of the GMAT variable is in the wrong direction. You will notice that it is negative. This tells us that it has a slight negative impact on the odds of being admitted. You will also notice if you leave the GMAT variable out that the coeficent for GPA swaps diection.\n",
    "\n",
    "\n",
    "\n",
    "Another, issue is we do not have a intercept. You will see that if you swap the intercept with the gmat variable we get a Pseudo $R^2$ of 1. Also when we examine the Accuracy of this model we get a perfect score. One needs to be very careful when picking a model like this as you cannot be sure that the this model would scale very well. A real point to be worried about with this model is the size of the standard errors for all the variables including the intercept.\n",
    "\n",
    "You could argue that if you have a zero GPA, GMAT and work experience then you would expect the odds of being addmitted being zero.\n",
    "\n",
    "If you add a constant into the model you will find that it fails. This usually occurs because the model is overspecified or unstable, and can mean that a number of variables/predictors are highly correlated with the intercept, or you have to many variables in the model or the dataset is to small.\n",
    "\n",
    "Also, most importantly you will notice the standard error inflates dramitically when we include an intercept, thus we cannot definitively tell which variables are useful. Taking all of this evidence into account would suggest we ignore the intercept term.\n",
    "\n",
    "We will now examine the accuracy, F1 score and the AUC.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1726433494797,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "noQ0HocZEuYH",
    "outputId": "14abb5a5-cb69-4a0f-e07e-fb0891b1c771"
   },
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y, np.round_(logit.predict(),0), rownames=['Actual'], colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOxF6Q5nExSS"
   },
   "source": [
    "In the following code window we can run a clasification report which gives a number of statistics. The explaination for these statistics is as follows:\n",
    "\n",
    "* accuracy (correct decisions/total no. of decisions)\n",
    "* precision (True positives/(True Positives+False Positivies))\n",
    "* recall (True positives/(True Positives + False Negatives))\n",
    "* f1-scrore (Formula including precision and recall)\n",
    "* support (The number of items in the class)\n",
    "\n",
    "In classification problems we need to be very careful not to over rely on the accuracy score. It can often be the case that a high accuracy could be found, however, we may need to put more emphasis on identifying a particular class. So for example if we were trying to identify critically ill patients from a rare disease we would most likely get a high accuaracy as we would identify the majority of patients who were not ill, but diagnose someone as not being ill when in fact they are seriously ill. This is the reason why some authors report a F1-score. However, this to has been criticized has it treats precision and recall equally.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1726433502028,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "VTNgzhDFE1ZB",
    "outputId": "edd5f1d4-4681-49f0-f542-1b275f4ece41"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, np.round_(logit.predict(),0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QhMRn7aE4yx"
   },
   "source": [
    "Finally for logistic regression models we should build a Receiver Operating Characteristic (ROC) curve and determine the Area Under the Curve (AUC)\n",
    "A ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The ROC curve is created by plotting the true positive rate against the false positive rate at various threshold settings. The higher the AUC the better the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1726433513073,
     "user": {
      "displayName": "Andrew Mccarren",
      "userId": "16186536572019350587"
     },
     "user_tz": -60
    },
    "id": "k9CZZhkJE_gy",
    "outputId": "2c6de458-7d70-4ea1-916b-7ca0b5f5d559"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y, logit.predict(X))\n",
    "fpr, tpr, thresholds = roc_curve(y, logit.predict(X))\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6W698p1FDQq"
   },
   "source": [
    "So we have only really shown how to run the logistic model, but we have not really examined the formula for it or the interpretation of the parameter estimates. We will address these issues in MOOC5 when we introduce the theory behind Generalised Linear Model.\n",
    "\n",
    "Finally, you will all want to try to predict class or continous variables. If you are doing this run the models on a \"training\" set. This is a subset of your data that your models will be trained on. The remaining part of the data will be treated as a test set. When your model is finalised on the training set you will then test it on your test set. There are a number of ways to select training and test sets and you always have to make sure they are properly balanced. You will learn a lot more about this in Machine Learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
