{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make CSV for nasdeq\n",
    "# === 1) locate dataset root ===\n",
    "\n",
    "base_root = Path.home() / \"csc1171\" / \"data\" / \"raw\"\n",
    "dataset_dir_name = \"amex_nyse_nasdaq_stock_histories\"\n",
    "\n",
    "dataset_dir = None\n",
    "if base_root.exists():\n",
    "    for p in base_root.iterdir():\n",
    "        if p.is_dir() and p.name.lower() == dataset_dir_name:\n",
    "            dataset_dir = p\n",
    "if dataset_dir is None:\n",
    "    # fallback (may not exist on some systems; edit as needed)\n",
    "    dataset_dir = base_root / dataset_dir_name\n",
    "\n",
    "symbols_file = dataset_dir / \"all_symbols.txt\"\n",
    "output_file = dataset_dir / \"clean_company_listings.csv\"\n",
    "\n",
    "# === 2) load tickers ===\n",
    "with open(symbols_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    symbols = [ln.strip().lower() for ln in f if ln.strip() and not ln.startswith(\"#\")]\n",
    "\n",
    "# === 3) scan once: index all csv files by symbol (case-insensitive) ===\n",
    "# if multiple files exist for a symbol, prefer paths that include amex/nasdaq/nyse\n",
    "def score_path_for_exchange(p: Path):\n",
    "    parts = [x.lower() for x in p.parts]\n",
    "    bonus = 0\n",
    "    for exch in (\"amex\", \"nasdaq\", \"nyse\"):\n",
    "        if exch in parts:\n",
    "            bonus += 10\n",
    "    # lower score is better; negative bonus wins\n",
    "    return (-bonus, len(p.parts))\n",
    "\n",
    "symbol_to_path = {}\n",
    "if dataset_dir.exists():\n",
    "    csv_files = list(dataset_dir.rglob(\"*.csv\"))\n",
    "    csv_files.sort(key=score_path_for_exchange)\n",
    "    for p in csv_files:\n",
    "        sym = p.stem.lower()\n",
    "        if sym not in symbol_to_path:\n",
    "            symbol_to_path[sym] = p\n",
    "\n",
    "# === 4) build a {symbol -> company name} map from likely metadata files ===\n",
    "meta_patterns = [\n",
    "    \"*symbols_valid_meta*.csv\",\n",
    "    \"*nasdaq_screener*.csv\",\n",
    "    \"*companylist*.csv\",\n",
    "    \"*symbols*.csv\",\n",
    "    \"*companies*.csv\",\n",
    "    \"*metadata*.csv\",\n",
    "]\n",
    "\n",
    "name_col_candidates = [\n",
    "    (\"symbol\", \"name\"),\n",
    "    (\"symbol\", \"security name\"),\n",
    "    (\"symbol\", \"company name\"),\n",
    "    (\"ticker\", \"name\"),\n",
    "    (\"ticker\", \"security name\"),\n",
    "    (\"ticker\", \"company name\"),\n",
    "]\n",
    "\n",
    "symbol_to_name = {}\n",
    "\n",
    "def try_read_csv_any_sep(path: Path):\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        for sep in (\"|\", \"\\t\", \";\"):\n",
    "            try:\n",
    "                return pd.read_csv(path, sep=sep)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "for pattern in meta_patterns:\n",
    "    for meta_path in dataset_dir.rglob(pattern):\n",
    "        dfm = try_read_csv_any_sep(meta_path)\n",
    "        if dfm is None or dfm.empty:\n",
    "            continue\n",
    "        cols_lc = {c.lower(): c for c in dfm.columns}\n",
    "        matched = False\n",
    "        for sym_col, name_col in name_col_candidates:\n",
    "            if sym_col in cols_lc and name_col in cols_lc:\n",
    "                sc, nc = cols_lc[sym_col], cols_lc[name_col]\n",
    "                sub = dfm[[sc, nc]].dropna()\n",
    "                for _, r in sub.iterrows():\n",
    "                    s = str(r[sc]).strip().lower()\n",
    "                    n = str(r[nc]).strip()\n",
    "                    if s and n and s not in symbol_to_name:\n",
    "                        symbol_to_name[s] = n\n",
    "                matched = True\n",
    "                break\n",
    "        if matched:\n",
    "            continue\n",
    "\n",
    "# === 5) helpers for exchange, earliest date, and name-in-file ===\n",
    "def infer_exchange_from_path(p: Path) -> str:\n",
    "    parts = [x.lower() for x in p.parts]\n",
    "    for exch in (\"amex\", \"nasdaq\", \"nyse\"):\n",
    "        if exch in parts:\n",
    "            return exch.upper()  # output text can be uppercase in data; rule is about code\n",
    "    pdn = p.parent.name\n",
    "    return pdn.upper() if pdn.lower() in (\"amex\", \"nasdaq\", \"nyse\") else \"\"\n",
    "\n",
    "def earliest_date_from_csv(p: Path) -> str:\n",
    "    try:\n",
    "        head = try_read_csv_any_sep(p)\n",
    "        if head is None or head.empty:\n",
    "            return \"\"\n",
    "        cols = [c.lower() for c in head.columns]\n",
    "        date_candidates = (\"date\", \"timestamp\")\n",
    "        dcol = None\n",
    "        for c in head.columns:\n",
    "            if c.lower() in date_candidates:\n",
    "                dcol = c\n",
    "                break\n",
    "        if dcol is None:\n",
    "            return \"\"\n",
    "        df = try_read_csv_any_sep(p)\n",
    "        if df is None or df.empty or dcol not in df.columns:\n",
    "            return \"\"\n",
    "        dt = pd.to_datetime(df[dcol], errors=\"coerce\")\n",
    "        return dt.min().date().isoformat() if dt.notna().any() else \"\"\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def try_name_from_file(p: Path) -> str:\n",
    "    try:\n",
    "        df = try_read_csv_any_sep(p)\n",
    "        if df is None or df.empty:\n",
    "            return \"\"\n",
    "        for c in df.columns:\n",
    "            if c.lower() in (\"name\", \"company\", \"security name\", \"company name\"):\n",
    "                s = df[c].dropna()\n",
    "                return str(s.iloc[0]).strip() if len(s) else \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "# === 6) build the output table ===\n",
    "rows = []\n",
    "for sym in symbols:\n",
    "    rec = {\n",
    "        \"company name\": symbol_to_name.get(sym, \"\"),\n",
    "        \"symbol (acronym)\": sym.upper(),  # output text can be uppercase\n",
    "        \"date of listing\": \"\",\n",
    "        \"stock offering\": \"\",\n",
    "    }\n",
    "    p = symbol_to_path.get(sym)\n",
    "    if p is not None:\n",
    "        rec[\"stock offering\"] = infer_exchange_from_path(p)\n",
    "        rec[\"date of listing\"] = earliest_date_from_csv(p)\n",
    "        if not rec[\"company name\"]:\n",
    "            nm = try_name_from_file(p)\n",
    "            if nm:\n",
    "                rec[\"company name\"] = nm\n",
    "    rows.append(rec)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"company name\", \"symbol (acronym)\", \"date of listing\", \"stock offering\"])\n",
    "df.sort_values(by=[\"symbol (acronym)\", \"date of listing\"], inplace=True, ignore_index=True)\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"wrote: {output_file}\")\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
