{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5910a70-f188-414b-9b30-2404dfb5bdfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, re, pandas as pd, numpy as np\n",
    "from pandas.tseries.holiday import (\n",
    "    AbstractHolidayCalendar, Holiday, nearest_workday, USFederalHolidayCalendar,\n",
    "    GoodFriday, EasterMonday\n",
    ")\n",
    "from pandas.tseries.offsets import CustomBusinessDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6758815-fcf6-4b1c-9bcd-08a8583a4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds: company name, symbol (acronym), date of listing, stock offering\n",
    "\n",
    "dataset_dir = os.path.expanduser(\"~/csc1171/data/raw/AMEX_NYSE_NASDAQ_stock_histories\")\n",
    "symbols_file = os.path.join(dataset_dir, \"all_symbols.txt\")\n",
    "big_file = os.path.join(dataset_dir, \"fh_5yrs.csv\")\n",
    "output_file = os.path.expanduser(\"~/csc1171/notebooks/Dominik/clean_company_listings.csv\")\n",
    "full_dir = os.path.join(dataset_dir, \"full_history\")\n",
    "\n",
    "\n",
    "with open(symbols_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    symbols = [ln.strip().upper() for ln in f if ln.strip() and not ln.startswith(\"#\")]\n",
    "symset = set(symbols)\n",
    "use_full = os.path.isdir(full_dir)\n",
    "\n",
    "# build lookup maps from nasdaq symbol directory files\n",
    "nasdaq_file = os.path.join(dataset_dir, \"nasdaqlisted.txt\")\n",
    "other_file = os.path.join(dataset_dir, \"otherlisted.txt\")\n",
    "\n",
    "name_map, exch_map = {}, {}\n",
    "\n",
    "if os.path.isfile(nasdaq_file):\n",
    "    nl = pd.read_csv(nasdaq_file, sep=\"|\")\n",
    "    if \"Symbol\" in nl.columns and \"Security Name\" in nl.columns:\n",
    "        nl = nl[nl[\"Symbol\"] != \"File Creation Time\"]\n",
    "        for _, r in nl.iterrows():\n",
    "            s = str(r[\"Symbol\"]).upper()\n",
    "            name_map[s] = str(r[\"Security Name\"]).strip()\n",
    "            exch_map[s] = \"NASDAQ\"\n",
    "\n",
    "if os.path.isfile(other_file):\n",
    "    ol = pd.read_csv(other_file, sep=\"|\")\n",
    "    col = {c.lower(): c for c in ol.columns}\n",
    "    symcol = col.get(\"act symbol\") or col.get(\"symbol\")\n",
    "    namecol = col.get(\"security name\") or col.get(\"name\")\n",
    "    excol = col.get(\"exchange\")\n",
    "    if symcol and namecol and excol:\n",
    "        ol = ol[ol[symcol] != \"File Creation Time\"]\n",
    "        xmap = {\"A\": \"AMEX\", \"N\": \"NYSE\", \"P\": \"NYSE ARCA\", \"Q\": \"NASDAQ\", \"Z\": \"BATS\"}\n",
    "        for _, r in ol.iterrows():\n",
    "            s = str(r[symcol]).upper()\n",
    "            name_map.setdefault(s, str(r[namecol]).strip())\n",
    "            exch_raw = str(r[excol]).strip().upper()\n",
    "            exch_map.setdefault(s, xmap.get(exch_raw, exch_raw))\n",
    "\n",
    "\n",
    "def detect_cols(df):\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    s = cols.get(\"symbol\") or cols.get(\"ticker\")\n",
    "    d = cols.get(\"date\") or cols.get(\"timestamp\")\n",
    "    e = cols.get(\"exchange\")\n",
    "    n = cols.get(\"name\") or cols.get(\"security name\") or cols.get(\"company name\")\n",
    "    return s, d, e, n\n",
    "\n",
    "min_date = {}\n",
    "first_ex = {}\n",
    "first_name = {}\n",
    "\n",
    "probe = pd.read_csv(big_file, nrows=5)\n",
    "scol, dcol, ecol, ncol = detect_cols(probe)\n",
    "\n",
    "if use_full:\n",
    "    for s in symbols:\n",
    "        p = os.path.join(full_dir, f\"{s}.csv\")\n",
    "        if os.path.isfile(p):\n",
    "            hdr = pd.read_csv(p, nrows=1)\n",
    "            dcol = next((c for c in hdr.columns if c.lower() == \"date\"), None)\n",
    "            if dcol:\n",
    "                d = pd.read_csv(p, usecols=[dcol])[dcol]\n",
    "                d = pd.to_datetime(d, errors=\"coerce\").dropna()\n",
    "                if len(d):\n",
    "                    min_date[s] = d.min()\n",
    "\n",
    "else:\n",
    "    probe = pd.read_csv(big_file, nrows=5)\n",
    "    scol, dcol, ecol, ncol = detect_cols(probe)\n",
    "\n",
    "    for chunk in pd.read_csv(big_file, usecols=[c for c in [scol, dcol, ecol, ncol] if c], chunksize=500000):\n",
    "        chunk[scol] = chunk[scol].astype(str).str.upper()\n",
    "        chunk = chunk[chunk[scol].isin(symset)]\n",
    "        if not len(chunk):\n",
    "            continue\n",
    "        dt = pd.to_datetime(chunk[dcol], errors=\"coerce\")\n",
    "        chunk = chunk.loc[dt.notna()].copy()\n",
    "        chunk[\"_dt\"] = dt[dt.notna()]\n",
    "        mins = chunk.groupby(scol)[\"_dt\"].min()\n",
    "        for s, d in mins.items():\n",
    "            if (s not in min_date) or (d < min_date[s]):\n",
    "                min_date[s] = d\n",
    "        if ecol:\n",
    "            for s, ex in chunk[[scol, ecol]].dropna().drop_duplicates(subset=[scol]).itertuples(index=False):\n",
    "                if s not in first_ex:\n",
    "                    first_ex[s] = str(ex).upper()\n",
    "        if ncol:\n",
    "            for s, nm in chunk[[scol, ncol]].dropna().drop_duplicates(subset=[scol]).itertuples(index=False):\n",
    "                if s not in first_name:\n",
    "                    first_name[s] = str(nm).strip()\n",
    "\n",
    "\n",
    "rows = []\n",
    "# for s in symbols:\n",
    "#     rows.append({\n",
    "#         \"company name\": first_name.get(s, name_map.get(s, \"\")),\n",
    "#         \"symbol (acronym)\": s,\n",
    "#         \"date of listing\": (min_date.get(s).date().isoformat() if s in min_date else \"\"),\n",
    "#         \"stock offering\": first_ex.get(s, exch_map.get(s, \"\")),\n",
    "#     })\n",
    "for s in symbols:\n",
    "    s_raw = s\n",
    "    alts = {s_raw, s_raw.replace('.', '-'), s_raw.replace('-', '.')}\n",
    "    rows.append({\n",
    "        \"company name\": (first_name.get(s) or next((name_map[a] for a in alts if a in name_map), \"\")),\n",
    "        \"symbol (acronym)\": s,\n",
    "        \"date of listing\": (min_date.get(s).date().isoformat() if s in min_date else \"\"),\n",
    "        \"stock offering\": (first_ex.get(s) or next((exch_map[a] for a in alts if a in exch_map), \"\")),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows, columns=[\"company name\",\"symbol (acronym)\",\"date of listing\",\"stock offering\"]).to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c080408f-0d8c-4109-af87-46d5d2a57eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix names and dtypes\n",
    "\n",
    "STANDARD_COLS = {\n",
    "    \"open\":\"open\",\"o\":\"open\",\n",
    "    \"high\":\"high\",\"h\":\"high\",\n",
    "    \"low\":\"low\",\"l\":\"low\",\n",
    "    \"close\":\"close\",\"c\":\"close\",\"last\":\"close\",\"adjclose\":\"adj_close\",\"adj_close\":\"adj_close\",\"adjusted_close\":\"adj_close\",\n",
    "    \"volume\":\"volume\",\"vol\":\"volume\",\"shares_traded\":\"volume\",\n",
    "    \"date\":\"date\",\"timestamp\":\"date\",\"time\":\"date\",\"trade_date\":\"date\",\n",
    "    \"symbol\":\"symbol\",\"ticker\":\"symbol\",\n",
    "    \"exchange\":\"exchange\",\"market\":\"exchange\",\"stock_offering\":\"exchange\",\n",
    "    \"currency\":\"currency\"\n",
    "}\n",
    "\n",
    "STANDARD_COLS.update({\n",
    "    \"adj_close\":\"adj_close\",\n",
    "    \"adj_close_\":\"adj_close\",\n",
    "    \"adj__close\":\"adj_close\",\n",
    "})\n",
    "\n",
    "PRICE_COLS = [\"open\",\"high\",\"low\",\"close\",\"adj_close\"]\n",
    "INT_COLS = [\"volume\"]\n",
    "CAT_COLS = [\"exchange\",\"currency\"]\n",
    "REQ_DATE = \"date\"\n",
    "REQ_SYMBOL = \"symbol\"\n",
    "\n",
    "def _snake(s:str)->str:\n",
    "    s = re.sub(r\"[^\\w]+\",\"_\", s.strip().lower())\n",
    "    s = re.sub(r\"_+\",\"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "def normalize_columns(df:pd.DataFrame)->pd.DataFrame:\n",
    "    colmap = {}\n",
    "    for c in df.columns:\n",
    "        k = _snake(c)\n",
    "        k = STANDARD_COLS.get(k, k)\n",
    "        colmap[c] = k\n",
    "    df = df.rename(columns=colmap)\n",
    "    if len(set(df.columns)) != len(df.columns):\n",
    "        agg = {}\n",
    "        for c in df.columns:\n",
    "            if c not in agg: agg[c] = lambda x: x.bfill().ffill().iloc[0] if hasattr(x,\"bfill\") else x\n",
    "        df = df.groupby(axis=1, level=0).first()\n",
    "    return df\n",
    "\n",
    "# def parse_date_col(df:pd.DataFrame)->pd.DataFrame:\n",
    "#     if REQ_DATE not in df.columns: return df\n",
    "#     # coerce strings like 'YYYY-MM-DD', 'MM/DD/YYYY', 'YYYY-MM-DD HH:MM:SS', etc.\n",
    "#     dt = pd.to_datetime(df[REQ_DATE], errors=\"coerce\", utc=True)\n",
    "#     # if parsed tz-naive, convert to UTC; if already tz-aware, keep UTC\n",
    "#     if dt.dtype == \"datetime64[ns, UTC]\":\n",
    "#         df[REQ_DATE] = dt\n",
    "#     else:\n",
    "#         df[REQ_DATE] = pd.to_datetime(df[REQ_DATE], errors=\"coerce\").dt.tz_localize(\"UTC\")\n",
    "#     return df\n",
    "\n",
    "def parse_date_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if REQ_DATE not in df.columns:\n",
    "        return df\n",
    "    dt = pd.to_datetime(df[REQ_DATE], errors=\"coerce\", utc=False)\n",
    "    # If tz-aware, convert to UTC; if naive, localize to UTC.\n",
    "    if getattr(dt.dt, \"tz\", None) is not None:\n",
    "        dt = dt.dt.tz_convert(\"UTC\")\n",
    "    else:\n",
    "        dt = dt.dt.tz_localize(\"UTC\")\n",
    "    df[REQ_DATE] = dt\n",
    "    return df\n",
    "\n",
    "\n",
    "def coerce_numeric(df:pd.DataFrame)->pd.DataFrame:\n",
    "    for c in PRICE_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = (df[c].astype(str).str.replace(\",\",\"\",regex=False)\n",
    "                              .str.replace(\" \",\"\",regex=False)\n",
    "                              .str.replace(\"$\",\"\",regex=False)\n",
    "                              .replace([\"\", \"nan\",\"None\"], np.nan)\n",
    "                              .astype(float))\n",
    "    for c in INT_COLS:\n",
    "        if c in df.columns:\n",
    "            ser = df[c].astype(str).str.replace(\",\",\"\",regex=False).str.replace(\" \",\"\",regex=False)\n",
    "            ser = ser.replace([\"\", \"nan\",\"None\"], np.nan)\n",
    "\n",
    "            ser = pd.to_numeric(ser, errors=\"coerce\")\n",
    "            if ser.notna().any() and (ser.dropna() % 1 == 0).all():\n",
    "                df[c] = ser.astype(\"Int64\")\n",
    "            else:\n",
    "                df[c] = ser.astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def tidy_symbol(df:pd.DataFrame, symbol_hint:str|None=None)->pd.DataFrame:\n",
    "    if REQ_SYMBOL not in df.columns and symbol_hint:\n",
    "        df[REQ_SYMBOL] = symbol_hint\n",
    "    if REQ_SYMBOL in df.columns:\n",
    "        df[REQ_SYMBOL] = (df[REQ_SYMBOL].astype(str).str.upper().str.strip()\n",
    "                          .str.replace(\"\\u200b\",\"\",regex=False))\n",
    "        df = df[df[REQ_SYMBOL]!=\"\"]\n",
    "    return df\n",
    "\n",
    "def cat_types(df:pd.DataFrame)->pd.DataFrame:\n",
    "    for c in CAT_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "            df.loc[df[c].isin([\"\", \"nan\",\"None\"]), c] = np.nan\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "def finalize_schema(df:pd.DataFrame)->pd.DataFrame:\n",
    "    # Ensure all price cols exist even if missing in source\n",
    "    for c in PRICE_COLS:\n",
    "        if c not in df.columns: df[c] = np.nan\n",
    "    for c in INT_COLS:\n",
    "        if c not in df.columns: df[c] = pd.Series(pd.array([pd.NA]*len(df), dtype=\"Int64\"))\n",
    "    if \"adj_close\" in df.columns and df[\"adj_close\"].isna().all() and \"close\" in df.columns:\n",
    "        df[\"adj_close\"] = df[\"close\"].astype(\"float64\")\n",
    "    if REQ_DATE in df.columns:\n",
    "        df = df[df[REQ_DATE].notna()]\n",
    "    if REQ_SYMBOL in df.columns:\n",
    "        df = df[df[REQ_SYMBOL].notna() & (df[REQ_SYMBOL]!=\"\")]\n",
    "    keep_order = [x for x in [REQ_DATE,REQ_SYMBOL,\"exchange\",\"currency\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"] if x in df.columns]\n",
    "    others = [c for c in df.columns if c not in keep_order]\n",
    "    df = df[keep_order+others]\n",
    "    df = df.drop_duplicates(subset=[c for c in [REQ_DATE, REQ_SYMBOL] if c in df.columns]).sort_values(by=[c for c in [REQ_DATE, REQ_SYMBOL] if c in df.columns])\n",
    "    # Assert dtypes\n",
    "    for c in PRICE_COLS:\n",
    "        if c in df.columns: df[c] = df[c].astype(\"float64\")\n",
    "    if \"volume\" in df.columns: df[\"volume\"] = df[\"volume\"].astype(\"Int64\")\n",
    "    if \"symbol\" in df.columns: df[\"symbol\"] = df[\"symbol\"].astype(\"object\")\n",
    "    if \"source\" in df.columns: df[\"source\"] = df[\"source\"].astype(\"object\")\n",
    "    if \"date\" in df.columns and df[\"date\"].dtype.tz is None:\n",
    "        df[\"date\"] = df[\"date\"].dt.tz_localize(\"UTC\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def looks_like_returns_matrix(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristic: has 'date' but no OHLC columns, and >3 other columns (strategies).\n",
    "    Good for HF.csv (EDHEC) style monthly returns panel.\n",
    "    \"\"\"\n",
    "    cols = set(df.columns.str.lower())\n",
    "    has_date = \"date\" in cols\n",
    "    has_ohlc = bool(cols & {\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\",\"symbol\"})\n",
    "    many_wide_cols = (len(cols) >= 5) # date + many strategy columns\n",
    "    return has_date and (not has_ohlc) and many_wide_cols\n",
    "\n",
    "def clean_edhec_returns(df_raw: pd.DataFrame, source: str = \"EDHEC\") -> pd.DataFrame:\n",
    "    df = df_raw.rename(columns={str(c): str(c).strip() for c in df_raw.columns})\n",
    "    # Parse date to UTC\n",
    "    df = df.rename(columns={\"date\":\"date\"})\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", utc=True)\n",
    "    df = df[df[\"date\"].notna()].copy()\n",
    "\n",
    "    value_cols = [c for c in df.columns if c != \"date\"]\n",
    "    df = df.melt(id_vars=[\"date\"], value_vars=value_cols,\n",
    "                 var_name=\"symbol\", value_name=\"ret\")\n",
    "\n",
    "    df[\"symbol\"] = (df[\"symbol\"].astype(str)\n",
    "                    .str.replace(\".\", \"_\", regex=False)\n",
    "                    .str.strip().str.upper())\n",
    "    df[\"ret\"] = pd.to_numeric(df[\"ret\"], errors=\"coerce\").astype(\"float64\")\n",
    "    df = df.dropna(subset=[\"symbol\",\"ret\"]).sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "    df[\"source\"] = source\n",
    "    df[\"symbol\"] = df[\"symbol\"].astype(\"object\")\n",
    "    df[\"source\"] = df[\"source\"].astype(\"object\")\n",
    "    # Ensure tz-aware UTC (pd.to_datetime(utc=True) already does, but belt & braces)\n",
    "    if getattr(df[\"date\"].dt, \"tz\", None) is None:\n",
    "        df[\"date\"] = df[\"date\"].dt.tz_localize(\"UTC\")\n",
    "    return df[[\"date\",\"symbol\",\"ret\",\"source\"]]\n",
    "\n",
    "def clean_any(df: pd.DataFrame, source: str, symbol_hint: str | None = None) -> pd.DataFrame:\n",
    "    cols_lower = set(map(str.lower, df.columns))\n",
    "    if looks_like_returns_matrix(df.rename(columns=str.lower)):\n",
    "        return clean_edhec_returns(df, source=source)\n",
    "    return clean_names_and_dtypes(df, source=source, symbol_hint=symbol_hint)\n",
    "\n",
    "def clean_names_and_dtypes(df:pd.DataFrame, source:str, symbol_hint:str|None=None)->pd.DataFrame:\n",
    "    df = normalize_columns(df)\n",
    "    df = tidy_symbol(df, symbol_hint)\n",
    "    df = parse_date_col(df)\n",
    "    df = coerce_numeric(df)\n",
    "    df = cat_types(df)\n",
    "    df[\"source\"] = source\n",
    "    return finalize_schema(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32f0c02-0c84-47a4-b56f-6789a423f533",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FH5 === (6852038, 9)\n",
      "date         datetime64[ns, UTC]\n",
      "symbol                    object\n",
      "open                     float64\n",
      "high                     float64\n",
      "low                      float64\n",
      "close                    float64\n",
      "adj_close                float64\n",
      "volume                     Int64\n",
      "source                    object\n",
      "dtype: object\n",
      "                       date symbol        open        high         low  \\\n",
      "0 2015-01-02 00:00:00+00:00   AADR   37.250000   37.250000   36.639999   \n",
      "1 2015-01-02 00:00:00+00:00    AAL   54.279999   54.599998   53.070000   \n",
      "2 2015-01-02 00:00:00+00:00   AAMC  308.000000  348.589996  308.000000   \n",
      "3 2015-01-02 00:00:00+00:00   AAME    3.990000    4.030000    3.980000   \n",
      "4 2015-01-02 00:00:00+00:00    AAN   30.809999   30.860001   30.040001   \n",
      "\n",
      "        close   adj_close    volume source  \n",
      "0   36.639999   35.399769      2000    FH5  \n",
      "1   53.910000   51.079918  10748600    FH5  \n",
      "2  327.179993  327.179993     11500    FH5  \n",
      "3    4.030000    3.917722     11400    FH5  \n",
      "4   30.620001   30.058821    898900    FH5  \n",
      "\n",
      "=== EDHEC === (3419, 4)\n",
      "date      datetime64[ns, UTC]\n",
      "symbol                 object\n",
      "ret                   float64\n",
      "source                 object\n",
      "dtype: object\n",
      "                       date                 symbol     ret source\n",
      "0 1997-01-31 00:00:00+00:00  CONVERTIBLE_ARBITRAGE  0.0119  EDHEC\n",
      "1 1997-02-28 00:00:00+00:00  CONVERTIBLE_ARBITRAGE  0.0123  EDHEC\n",
      "2 1997-03-31 00:00:00+00:00  CONVERTIBLE_ARBITRAGE  0.0078  EDHEC\n",
      "3 1997-04-30 00:00:00+00:00  CONVERTIBLE_ARBITRAGE  0.0086  EDHEC\n",
      "4 1997-05-31 00:00:00+00:00  CONVERTIBLE_ARBITRAGE  0.0156  EDHEC\n"
     ]
    }
   ],
   "source": [
    "# Test names dtypes \n",
    "\n",
    "# # 1) Load\n",
    "# p = os.path.expanduser(\"~/csc1171/data/raw/SP500_ETF_FX_Crypto_Daily/AAPL.csv\")\n",
    "# df_raw = pd.read_csv(p)\n",
    "\n",
    "# # 2) Clean\n",
    "# df_clean = clean_names_and_dtypes(df_raw, source=\"Yahoo\", symbol_hint=\"AAPL\")\n",
    "\n",
    "# # 3) Inspect schema & a few rows\n",
    "# print(df_clean.dtypes)\n",
    "# print(df_clean.head(3))\n",
    "# print(df_clean[['date','symbol']].isna().sum())\n",
    "# print(df_clean[['open','high','low','close','adj_close','volume']].describe())\n",
    "\n",
    "# p = \"~/csc1171/data/raw/Global_Stock_Market_2008-2023/2008_Globla_Markets_Data.csv\"\n",
    "# df = pd.read_csv(os.path.expanduser(p))\n",
    "# df = clean_names_and_dtypes(df, source=\"Global\")\n",
    "# print(df.dtypes)\n",
    "\n",
    "# folder = os.path.expanduser(\"~/csc1171/data/raw/SP500_ETF_FX_Crypto_Daily\")\n",
    "# fn = \"JSM.csv\"\n",
    "# df = pd.read_csv(os.path.join(folder, fn))\n",
    "# df = clean_names_and_dtypes(df, source=\"Yahoo\", symbol_hint=os.path.splitext(fn)[0].upper())\n",
    "# print(df.dtypes)\n",
    "\n",
    "# p = \"~/csc1171/data/raw/AMEX_NYSE_NASDAQ_stock_histories/fh_5yrs.csv\"\n",
    "# df = pd.read_csv(os.path.expanduser(p))\n",
    "# df = clean_names_and_dtypes(df, source=\"FH5\")\n",
    "# print(df.dtypes)\n",
    "\n",
    "# import os, pandas as pd\n",
    "\n",
    "# # make wide prints readable\n",
    "# pd.set_option(\"display.width\", None)\n",
    "# pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "# def preview(df: pd.DataFrame, name: str):\n",
    "#     print(f\"\\n {name}\")\n",
    "#     print(\"shape:\", df.shape)\n",
    "#     print(\"dtypes:\\n\", df.dtypes.to_string())\n",
    "#     print(\"\\nhead(10):\")\n",
    "#     print(df.head(10))\n",
    "\n",
    "# # Global (prices)\n",
    "# p = os.path.expanduser(\"~/csc1171/data/raw/Global_Stock_Market_2008-2023/2008_Globla_Markets_Data.csv\")\n",
    "# df = pd.read_csv(p)\n",
    "# df = clean_any(df, source=\"Global\")\n",
    "# preview(df, \"Global\")\n",
    "\n",
    "# # Yahoo single-ticker (prices)\n",
    "# folder = os.path.expanduser(\"~/csc1171/data/raw/SP500_ETF_FX_Crypto_Daily\")\n",
    "# fn = \"JSM.csv\"\n",
    "# df = pd.read_csv(os.path.join(folder, fn))\n",
    "# df = clean_any(df, source=\"Yahoo\", symbol_hint=os.path.splitext(fn)[0].upper())\n",
    "# preview(df, \"Yahoo (JSM)\")\n",
    "\n",
    "# # FH panel (prices)\n",
    "# p = os.path.expanduser(\"~/csc1171/data/raw/AMEX_NYSE_NASDAQ_stock_histories/fh_5yrs.csv\")\n",
    "# df = pd.read_csv(p)\n",
    "# df = clean_any(df, source=\"FH5\")\n",
    "# preview(df, \"FH5\")\n",
    "\n",
    "# # EDHEC (returns)\n",
    "# p = os.path.expanduser(\"~/csc1171/data/raw/EDHEC_Hedge_Fund_Returns/HF.csv\")\n",
    "# df = pd.read_csv(p)\n",
    "# df = clean_any(df, source=\"EDHEC\")\n",
    "# preview(df, \"EDHEC (returns)\")\n",
    "\n",
    "# FH panel (prices)\n",
    "p = os.path.expanduser(\"~/csc1171/data/raw/AMEX_NYSE_NASDAQ_stock_histories/fh_5yrs.csv\")\n",
    "df = clean_any(pd.read_csv(p), source=\"FH5\")\n",
    "print(\"\\nFH5\", df.shape); print(df.dtypes); print(df.head(5))\n",
    "\n",
    "# EDHEC (returns)\n",
    "p = os.path.expanduser(\"~/csc1171/data/raw/EDHEC_Hedge_Fund_Returns/HF.csv\")\n",
    "df = clean_any(pd.read_csv(p), source=\"EDHEC\")\n",
    "print(\"\\n EDHEC\", df.shape); print(df.dtypes); print(df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3b5f9cf-a1ca-4bbf-9e6b-92253adf516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align offical trading calanders\n",
    "\n",
    "# Minimal NYSE holiday calendar (covers core exchange closures)\n",
    "class NYSEHolidayCalendar(AbstractHolidayCalendar):\n",
    "    rules = [\n",
    "        # New Year's Day\n",
    "        Holiday(\"NewYearsDay\", month=1, day=1, observance=nearest_workday),\n",
    "        # Martin Luther King Jr. Day (since 1998)\n",
    "        Holiday(\"MLK\", month=1, day=1, offset=pd.DateOffset(weekday=pd.offsets.WeekOfMonth(week=2, weekday=0)), start_date=\"1998-01-01\"),\n",
    "        # Washington's Birthday (Presidents' Day) – 3rd Monday in Feb\n",
    "        Holiday(\"PresidentsDay\", month=2, day=1, offset=pd.DateOffset(weekday=pd.offsets.WeekOfMonth(week=2, weekday=0))),\n",
    "        # Good Friday (NYSE closed)\n",
    "        GoodFriday,\n",
    "        # Memorial Day – last Monday in May\n",
    "        Holiday(\"MemorialDay\", month=5, day=31, offset=pd.DateOffset(weekday=pd.offsets.Week(weekday=0))),\n",
    "        # Juneteenth (since 2022), nearest workday\n",
    "        Holiday(\"Juneteenth\", month=6, day=19, observance=nearest_workday, start_date=\"2022-06-19\"),\n",
    "        # Independence Day\n",
    "        Holiday(\"IndependenceDay\", month=7, day=4, observance=nearest_workday),\n",
    "        # Labor Day – first Monday in September\n",
    "        Holiday(\"LaborDay\", month=9, day=1, offset=pd.DateOffset(weekday=pd.offsets.WeekOfMonth(week=0, weekday=0))),\n",
    "        # Thanksgiving – fourth Thursday in November\n",
    "        Holiday(\"Thanksgiving\", month=11, day=1, offset=pd.DateOffset(weekday=pd.offsets.WeekOfMonth(week=3, weekday=3))),\n",
    "        # Christmas Day\n",
    "        Holiday(\"Christmas\", month=12, day=25, observance=nearest_workday),\n",
    "    ]\n",
    "\n",
    "# build a sessions index for [start, end] inclusive\n",
    "# def trading_sessions(start: pd.Timestamp, end: pd.Timestamp, calendar: str = \"NYSE\", tz: str = \"UTC\") -> pd.DatetimeIndex:\n",
    "#     cal = NYSEHolidayCalendar() if calendar.upper() == \"NYSE\" else NYSEHolidayCalendar()\n",
    "#     cbd = CustomBusinessDay(calendar=cal)\n",
    "#     idx = pd.date_range(start=start.normalize(), end=end.normalize(), freq=cbd)\n",
    "#     # lock tz\n",
    "#     idx = pd.to_datetime(idx).tz_localize(\"UTC\").tz_convert(tz)\n",
    "#     return idx\n",
    "def trading_sessions(start: pd.Timestamp, end: pd.Timestamp, calendar: str = \"NYSE\", tz: str = \"UTC\") -> pd.DatetimeIndex:\n",
    "    cal = NYSEHolidayCalendar() if calendar.upper() == \"NYSE\" else NYSEHolidayCalendar()\n",
    "    cbd = CustomBusinessDay(calendar=cal)\n",
    "    idx = pd.date_range(start=start.normalize(), end=end.normalize(), freq=cbd)\n",
    "    if getattr(idx, \"tz\", None) is None:\n",
    "        idx = idx.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        idx = idx.tz_convert(\"UTC\")\n",
    "    return idx.tz_convert(tz)\n",
    "\n",
    "_OHLCV_AGG = {\n",
    "    \"open\": \"first\",\n",
    "    \"high\": \"max\",\n",
    "    \"low\": \"min\",\n",
    "    \"close\": \"last\",\n",
    "    \"adj_close\": \"last\",\n",
    "    \"volume\": \"sum\",\n",
    "}\n",
    "\n",
    "def _ensure_tz_utc(dt: pd.Series) -> pd.Series:\n",
    "    if getattr(dt.dt, \"tz\", None) is not None:\n",
    "        return dt.dt.tz_convert(\"UTC\")\n",
    "    else:\n",
    "        return dt.dt.tz_localize(\"UTC\")\n",
    "\n",
    "def _dedupe_ohlcv(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    keys = [c for c in [\"date\", \"symbol\"] if c in df.columns]\n",
    "    if not keys:\n",
    "        return df\n",
    "    agg = {c: fn for c, fn in _OHLCV_AGG.items() if c in df.columns}\n",
    "    others = [c for c in df.columns if c not in set(list(agg.keys()) + keys)]\n",
    "    agg.update({c: \"first\" for c in others})\n",
    "    out = (df.groupby(keys, as_index=False).agg(agg)\n",
    "             .sort_values(keys)\n",
    "             .reset_index(drop=True))\n",
    "    return out\n",
    "\n",
    "def align_to_trading_calendar(\n",
    "    df: pd.DataFrame,\n",
    "    calendar: str = \"NYSE\",\n",
    "    tz: str = \"UTC\",\n",
    "    fill: dict | None = None,\n",
    "    limit_fill: int | None = None,\n",
    "    clip_to_observed_span: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    if \"date\" not in df.columns:\n",
    "        return df.copy()\n",
    "    work = df.copy()\n",
    "    work[\"date\"] = _ensure_tz_utc(pd.to_datetime(work[\"date\"], errors=\"coerce\"))\n",
    "    work = work[work[\"date\"].notna()]\n",
    "    if \"symbol\" in work.columns:\n",
    "        work[\"symbol\"] = work[\"symbol\"].astype(str)\n",
    "\n",
    "    work[\"date\"] = work[\"date\"].dt.tz_convert(\"UTC\").dt.normalize()\n",
    "\n",
    "    if work.duplicated(subset=[\"symbol\",\"date\"], keep=False).sum() == 0:\n",
    "        print(\"[WARN] No (symbol,date) duplicates pre-dedupe; upstream may have dropped intraday rows already.\")\n",
    "\n",
    "    work = _dedupe_ohlcv(work)\n",
    "    if clip_to_observed_span and \"symbol\" in work.columns:\n",
    "        spans = (work.groupby(\"symbol\")[\"date\"].agg([\"min\", \"max\"])\n",
    "                 .rename(columns={\"min\":\"start\",\"max\":\"end\"}))\n",
    "        frames = []\n",
    "        for sym, (start, end) in spans.iterrows():\n",
    "            sess = trading_sessions(start, end, calendar=calendar, tz=\"UTC\")\n",
    "            g = work[work[\"symbol\"] == sym].set_index(\"date\").sort_index()\n",
    "            g = g.reindex(sess)\n",
    "            g[\"symbol\"] = sym\n",
    "            frames.append(g)\n",
    "        aligned = (pd.concat(frames, axis=0)\n",
    "                     .reset_index()\n",
    "                     .rename(columns={\"index\":\"date\"}))\n",
    "    else:\n",
    "        start, end = work[\"date\"].min(), work[\"date\"].max()\n",
    "        sess = trading_sessions(start, end, calendar=calendar, tz=\"UTC\")\n",
    "        aligned = (work.set_index(\"date\").sort_index()\n",
    "                        .groupby(\"symbol\", group_keys=True)\n",
    "                        .apply(lambda g: g.reindex(sess))\n",
    "                        .reset_index(level=0))\n",
    "        aligned = aligned.reset_index().rename(columns={\"index\":\"date\"})\n",
    "\n",
    "    if fill:\n",
    "        for col, how in fill.items():\n",
    "            if col not in aligned.columns:\n",
    "                continue\n",
    "            if how == \"ffill\":\n",
    "                aligned[col] = (aligned.groupby(\"symbol\", dropna=False)[col]\n",
    "                                .ffill(limit=limit_fill))\n",
    "            elif how == \"bfill\":\n",
    "                aligned[col] = (aligned.groupby(\"symbol\", dropna=False)[col]\n",
    "                                .bfill(limit=limit_fill))\n",
    "            elif how == \"fillna0\":\n",
    "                aligned[col] = aligned[col].fillna(0)\n",
    "\n",
    "    keep_order = [c for c in [\"date\",\"symbol\",\"exchange\",\"currency\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"] if c in aligned.columns]\n",
    "    other_cols = [c for c in aligned.columns if c not in keep_order]\n",
    "    aligned = aligned[keep_order + other_cols]\n",
    "\n",
    "    aligned[\"date\"] = aligned[\"date\"].dt.tz_convert(tz)\n",
    "\n",
    "    sort_keys = [c for c in [\"symbol\",\"date\"] if c in aligned.columns]\n",
    "    aligned = aligned.sort_values(sort_keys).reset_index(drop=True)\n",
    "\n",
    "    for c in [\"open\",\"high\",\"low\",\"close\",\"adj_close\"]:\n",
    "        if c in aligned.columns:\n",
    "            aligned[c] = aligned[c].astype(\"float64\")\n",
    "    if \"volume\" in aligned.columns:\n",
    "        aligned[\"volume\"] = pd.array(aligned[\"volume\"], dtype=\"Int64\")\n",
    "\n",
    "    return aligned\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73c8a66d-c119-4e95-a674-d2ecb8ec23cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW INPUT ===\n",
      "                        date symbol  open  high   low  close  adj_close  \\\n",
      "0        2024-07-03 16:00:00    ABC  10.0  11.0   9.0   10.8       10.8   \n",
      "1  2024-07-03 10:00:00-04:00    ABC  10.5  11.5   9.5   10.9       10.9   \n",
      "2        2024-07-04 16:00:00    ABC  11.0  12.0  10.0   11.8       11.8   \n",
      "3        2024-07-05 16:00:00    ABC  12.0  13.0  11.0   12.8       12.8   \n",
      "4        2024-07-06 16:00:00    ABC  12.5  13.5  11.5   12.9       12.9   \n",
      "5  2024-07-05 09:30:00-04:00    XYZ  20.0  21.0  19.0   20.5       20.5   \n",
      "\n",
      "   volume  \n",
      "0     100  \n",
      "1     150  \n",
      "2     200  \n",
      "3     300  \n",
      "4     400  \n",
      "5     500  \n",
      "[WARN] No (symbol,date) duplicates pre-dedupe; upstream may have dropped intraday rows already.\n",
      "\n",
      "=== AFTER ALIGNMENT (UTC, NYSE sessions only) ===\n",
      "                       date symbol  open  high   low  close  adj_close  volume\n",
      "0 2024-07-03 00:00:00+00:00    ABC  10.0  11.0   9.0   10.8       10.8     100\n",
      "1 2024-07-05 00:00:00+00:00    ABC  12.0  13.0  11.0   12.8       12.8     300\n",
      "\n",
      "Contains holiday 2024-07-04? -> False\n",
      "Contains Saturday 2024-07-06? -> False\n",
      "\n",
      "ABC 2024-07-03 -> open,high,low,close,volume: 10.0 11.0 9.0 10.8 100\n"
     ]
    }
   ],
   "source": [
    "# Testing (align offical trading calanders)\n",
    "\n",
    "# synthetic sample (weekend, holiday, duplicates)\n",
    "raw = pd.DataFrame({\n",
    "    \"date\": [\n",
    "        \"2024-07-03 16:00:00\", # ABC dup 1\n",
    "        \"2024-07-03 10:00:00-04:00\", # ABC dup 2 (same calendar day)\n",
    "        \"2024-07-04 16:00:00\", # NYSE holiday (Independence Day)\n",
    "        \"2024-07-05 16:00:00\", # trading day\n",
    "        \"2024-07-06 16:00:00\", # Saturday\n",
    "        \"2024-07-05 09:30:00-04:00\", # XYZ trading day\n",
    "    ],\n",
    "    \"symbol\": [\"ABC\",\"ABC\",\"ABC\",\"ABC\",\"ABC\",\"XYZ\"],\n",
    "    \"open\": [10, 10.5, 11, 12, 12.5, 20],\n",
    "    \"high\": [11, 11.5, 12, 13, 13.5, 21],\n",
    "    \"low\": [ 9, 9.5, 10, 11, 11.5, 19],\n",
    "    \"close\": [10.8,10.9, 11.8, 12.8,12.9, 20.5],\n",
    "    \"adj_close\":[10.8,10.9,11.8,12.8,12.9,20.5],\n",
    "    \"volume\": [100, 150, 200, 300, 400, 500],\n",
    "})\n",
    "\n",
    "print(raw)\n",
    "\n",
    "aligned = align_to_trading_calendar(raw, calendar=\"NYSE\", tz=\"UTC\")\n",
    "\n",
    "print(\"\\n(UTC, NYSE sessions only)\")\n",
    "print(aligned)\n",
    "\n",
    "print(\"\\nContains holiday 2024-07-04 ->\", any(\"2024-07-04\" in s for s in aligned[\"date\"].astype(str)))\n",
    "print(\"Contains Saturday 2024-07-06 ->\", any(\"2024-07-06\" in s for s in aligned[\"date\"].astype(str)))\n",
    "\n",
    "row_703 = aligned[(aligned[\"symbol\"]==\"ABC\") & (aligned[\"date\"].astype(str).str.startswith(\"2024-07-03\"))]\n",
    "if not row_703.empty:\n",
    "    r = row_703.iloc[0]\n",
    "    print(\"\\nABC 2024-07-03 -> open,high,low,close,volume:\", r[\"open\"], r[\"high\"], r[\"low\"], r[\"close\"], r[\"volume\"])\n",
    "else:\n",
    "    print(\"\\nABC 2024-07-03 row not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5a212cc-9a41-4199-9a01-8bea019ecfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading halts (same logic, with step-by-step prints) — FIXED\n",
    "def annotate_trading_halts(\n",
    "    df: pd.DataFrame,\n",
    "    price_cols=(\"open\",\"high\",\"low\",\"close\",\"adj_close\"),\n",
    "    symbol_col=\"symbol\",\n",
    "    date_col=\"date\",\n",
    "    market_open_mask: pd.Series | None = None,\n",
    "    span_mode: str = \"since_first\",\n",
    "    verbose: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    if verbose:\n",
    "        print(\"\\n annotate_trading_halts(): START\")\n",
    "        print(f\"Input rows: {len(df):,} | symbols: {df[symbol_col].nunique() if symbol_col in df else 'NA'}\")\n",
    "        if date_col in df:\n",
    "            print(f\"Date span: {df[date_col].min()} -> {df[date_col].max()}\")\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    any_price = out[list(price_cols)].notna().any(axis=1)\n",
    "    if verbose:\n",
    "        print(f\"Rows with ANY price present: {int(any_price.sum()):,}\")\n",
    "\n",
    "    sym_first = out.loc[any_price].groupby(symbol_col)[date_col].min()\n",
    "    sym_last = out.loc[any_price].groupby(symbol_col)[date_col].max()\n",
    "    if verbose:\n",
    "        print(f\"Symbols with ≥1 traded row: {len(sym_first):,}\")\n",
    "\n",
    "    out[\"_first_trade\"] = out[symbol_col].map(sym_first)\n",
    "    out[\"_last_trade\"] = out[symbol_col].map(sym_last)\n",
    "\n",
    "    if span_mode == \"first_to_last\":\n",
    "        if verbose: print('Span mode = \"first_to_last\"')\n",
    "        in_active_span = (\n",
    "            out[\"_first_trade\"].notna()\n",
    "            & out[\"_last_trade\"].notna()\n",
    "            & (out[date_col] >= out[\"_first_trade\"])\n",
    "            & (out[date_col] <= out[\"_last_trade\"])\n",
    "        )\n",
    "    else:\n",
    "        if verbose: print('Span mode = \"since_first\"')\n",
    "        in_active_span = out[\"_first_trade\"].notna() & (out[date_col] >= out[\"_first_trade\"])\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"in_active_span = True rows: {int(in_active_span.sum()):,}\")\n",
    "\n",
    "    no_prices = out[list(price_cols)].isna().all(axis=1)\n",
    "    if verbose:\n",
    "        print(f\"Rows where ALL price cols are NaN: {int(no_prices.sum()):,}\")\n",
    "\n",
    "    if market_open_mask is not None:\n",
    "        mok = market_open_mask.copy()\n",
    "        mok.index = pd.to_datetime(mok.index).tz_convert(out[date_col].dt.tz)\n",
    "        mapped = mok.reindex(out[date_col].values) # align by date values\n",
    "        mapped.index = out.index # align row index 1:1\n",
    "        open_flag = mapped.fillna(True).infer_objects(copy=False).astype(bool)\n",
    "        if verbose:\n",
    "            print(f\"market_open_mask provided. True rows: {int(open_flag.sum()):,}\")\n",
    "    else:\n",
    "        open_flag = pd.Series(True, index=out.index)\n",
    "        if verbose:\n",
    "            print(\"market_open_mask not provided assuming all trading-session dates were open\")\n",
    "\n",
    "    out[\"is_halt\"] = in_active_span & no_prices & open_flag\n",
    "    if verbose:\n",
    "        print(f\"HALT rows flagged (is_halt=True): {int(out['is_halt'].sum()):,}\")\n",
    "\n",
    "    prev = out.groupby(symbol_col)[\"is_halt\"].shift(fill_value=False)\n",
    "    block_start = out[\"is_halt\"] & ~prev\n",
    "    out[\"halt_block_id\"] = block_start.groupby(out[symbol_col]).cumsum()\n",
    "    out.loc[~out[\"is_halt\"], \"halt_block_id\"] = pd.NA\n",
    "    out[\"halt_len\"] = (\n",
    "        out[out[\"is_halt\"]]\n",
    "        .groupby([symbol_col, \"halt_block_id\"])[date_col]\n",
    "        .transform(\"count\")\n",
    "    ).fillna(0).astype(\"Int64\")\n",
    "    out = out.drop(columns=[\"_first_trade\",\"_last_trade\"])\n",
    "\n",
    "    if verbose:\n",
    "        sym_halts = (out.groupby(symbol_col)[\"is_halt\"].sum()).sort_values(ascending=False)\n",
    "        syms_with_halts = sym_halts[sym_halts > 0].index.tolist()\n",
    "        if syms_with_halts:\n",
    "            print(\"Halt summary\")\n",
    "            for s in syms_with_halts[:8]:\n",
    "                sub = out[(out[symbol_col]==s) & (out[\"is_halt\"])]\n",
    "                blocks = sub.groupby(\"halt_block_id\")[date_col].agg([\"min\",\"max\",\"count\"])\n",
    "                total = int(sub[\"is_halt\"].sum())\n",
    "                print(f\" {s}: {total} halt day(s), {len(blocks)} block(s)\")\n",
    "                for _, r in blocks.reset_index(drop=True).iterrows():\n",
    "                    print(f\"{r['min']} -> {r['max']}  (len={int(r['count'])})\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6dffb4be-d849-4cdf-93ae-824d3cdf9174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] No (symbol,date) duplicates pre-dedupe; upstream may have dropped intraday rows already.\n",
      "\n",
      "---- annotate_trading_halts(): START ----\n",
      "Input rows: 5 | symbols: 2\n",
      "Date span: 2024-07-02 00:00:00+00:00  ->  2024-07-08 00:00:00+00:00\n",
      "Rows with ANY price present: 4\n",
      "Symbols with ≥1 traded row: 2\n",
      "Span mode = \"since_first\"\n",
      "in_active_span = True rows: 5\n",
      "Rows where ALL price cols are NaN: 1\n",
      "market_open_mask provided. True rows: 5\n",
      "HALT rows flagged (is_halt=True): 1\n",
      "-- Halt summary (per symbol) --\n",
      "  ABC: 1 halt day(s), 1 block(s)\n",
      "    2024-07-05 00:00:00+00:00 -> 2024-07-05 00:00:00+00:00  (len=1)\n",
      "---- annotate_trading_halts(): END ----\n",
      "\n",
      "=== Aligned panel with halt annotations (focus window) ===\n",
      "                     date symbol  open  high  low  close  adj_close  volume  is_halt  halt_block_id  halt_len\n",
      "2024-07-02 00:00:00+00:00    ABC  10.0  11.0  9.0   10.8       10.8     100    False            NaN      <NA>\n",
      "2024-07-03 00:00:00+00:00    ABC  10.5  11.5  9.5   10.9       10.9     150    False            NaN      <NA>\n",
      "2024-07-05 00:00:00+00:00    ABC   NaN   NaN  NaN    NaN        NaN    <NA>     True            1.0         1\n",
      "2024-07-05 00:00:00+00:00    XYZ  20.0  21.0 19.0   20.5       20.5     500    False            NaN      <NA>\n",
      "\n",
      "Checks:\n",
      "- 2024-07-04 present?        -> False\n",
      "- 2024-07-06 present?        -> False\n",
      "- ABC halted on 2024-07-05?  -> True\n",
      "- XYZ traded on 2024-07-05?  -> True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2203137/2716920029.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  open_flag = mapped.fillna(True).infer_objects(copy=False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "# Test: annotate_trading_halts on a small panel\n",
    "\n",
    "# Synthetic intraday-ish data across an NYSE holiday (Jul 4) + weekend,\n",
    "# with one *halt* day for ABC (all prices missing on a real session) while XYZ trades.\n",
    "\n",
    "raw = pd.DataFrame({\n",
    "    \"date\": [\n",
    "        \"2024-07-02 16:00:00\", # both trade\n",
    "        \"2024-07-03 16:00:00\", # both trade\n",
    "        \"2024-07-04 16:00:00\", # NYSE holiday (should be removed by calendar)\n",
    "        \"2024-07-05 10:00:00\", # XYZ trades; ABC halted (no rows for ABC -> will be NaN after reindex)\n",
    "        \"2024-07-06 16:00:00\", # Saturday (removed)\n",
    "        \"2024-07-08 16:00:00\", # both trade\n",
    "    ],\n",
    "    \"symbol\": [\"ABC\",\"ABC\",\"ABC\",\"XYZ\",\"ABC\",\"ABC\"],\n",
    "    \"open\": [10, 10.5, 11, 20, 12.5, 13.0],\n",
    "    \"high\": [11, 11.5, 12, 21, 13.5, 14.0],\n",
    "    \"low\": [ 9, 9.5, 10, 19, 11.5, 12.0],\n",
    "    \"close\": [10.8,10.9, 11.8, 20.5,12.9, 13.5],\n",
    "    \"adj_close\":[10.8,10.9,11.8,20.5,12.9,13.5],\n",
    "    \"volume\": [100, 150, 200, 500, 400, 300],\n",
    "})\n",
    "\n",
    "aligned = align_to_trading_calendar(raw, calendar=\"NYSE\", tz=\"UTC\")\n",
    "def build_market_open_mask(panel, date_col=\"date\", price_cols=(\"open\",\"high\",\"low\",\"close\",\"adj_close\")):\n",
    "    return panel.groupby(date_col)[list(price_cols)].apply(lambda x: x.notna().any().any())\n",
    "\n",
    "mopen = build_market_open_mask(aligned)\n",
    "halted = annotate_trading_halts(aligned, market_open_mask=mopen)\n",
    "view = halted.loc[\n",
    "    (halted[\"date\"].astype(str) >= \"2024-07-02\") & (halted[\"date\"].astype(str) <= \"2024-07-08\"),\n",
    "    [\"date\",\"symbol\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\",\"is_halt\",\"halt_block_id\",\"halt_len\"]\n",
    "].sort_values([\"date\",\"symbol\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd68543-c687-4af4-9ddf-f7e8f8eb02e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
