{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "\n",
    "project_root = Path.cwd().parents[1]  # /home/ug/orlovsd2/csc1171\n",
    "data_dir = str((project_root / \"data/clean/SP500_ETF_FX_Crypto_Daily\").resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "project_root = Path.cwd().parents[1]  # /home/ug/orlovsd2/csc1171\n",
    "data_dir = str((project_root / \"data/clean/SP500_ETF_FX_Crypto_Daily\").resolve())\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"data_dir:\", data_dir)\n",
    "print(\"exists? ->\", os.path.exists(data_dir))\n",
    "print(\"train:\", len(glob.glob(os.path.join(data_dir, \"*_cleaned_2008_2020.csv\"))))\n",
    "print(\"test :\", len(glob.glob(os.path.join(data_dir, \"*_cleaned_2020_onward.csv\"))))\n",
    "print(\"first few (train):\", glob.glob(os.path.join(data_dir, \"*_cleaned_2008_2020.csv\"))[:5])\n",
    "print(\"first few (test) :\", glob.glob(os.path.join(data_dir, \"*_cleaned_2020_onward.csv\"))[:5])\n",
    "\n",
    "pairs = collect_train_test_pairs(data_dir, tickers=tickers_to_plot)\n",
    "print(f\"paired tickers: {len(pairs)}\")\n",
    "\n",
    "# for tkr, (train_path, test_path) in sorted(pairs.items()):\n",
    "#     df_tr = load_clean_csv(train_path)\n",
    "#     df_te = load_clean_csv(test_path)\n",
    "\n",
    "#     ret_tr = monthly_returns_from_real_close(df_tr)\n",
    "#     ret_te = monthly_returns_from_real_close(df_te)\n",
    "\n",
    "#     if ret_tr.empty and ret_te.empty:\n",
    "#         continue\n",
    "\n",
    "#     plot_ticker(tkr, ret_tr, ret_te, sigma, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# based on Frank's outlier test\n",
    "sigma = 3.0\n",
    "method = \"overall\"\n",
    "tickers_to_plot = None\n",
    "\n",
    "def load_clean_csv(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "    except ValueError:\n",
    "        df = pd.read_csv(path, index_col=0, parse_dates=[0])\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df = df.sort_index()\n",
    "    if \"date\" in df.columns and df.index.name is None:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.set_index(\"date\")\n",
    "    return df\n",
    "\n",
    "def returns_from_real_close(df, rule):\n",
    "    if \"real_close\" not in df.columns:\n",
    "        return pd.Series(dtype=float)\n",
    "    close_p = df[\"real_close\"].resample(rule).last()\n",
    "    ret_p = close_p.pct_change().dropna()\n",
    "    return ret_p\n",
    "\n",
    "def detect_outliers_overall(series, s):\n",
    "    mu = series.mean()\n",
    "    sd = series.std()\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return pd.Series(False, index=series.index)\n",
    "    z = (series - mu) / sd\n",
    "    return z.abs() > s\n",
    "\n",
    "def detect_outliers_seasonal(series, s):\n",
    "    df_ = pd.DataFrame({\"ret\": series})\n",
    "    df_[\"month\"] = df_.index.month\n",
    "    stats = df_.groupby(\"month\")[\"ret\"].agg([\"mean\", \"std\"])\n",
    "    mu = df_[\"month\"].map(stats[\"mean\"])\n",
    "    sd = df_[\"month\"].map(stats[\"std\"])\n",
    "    z = (df_[\"ret\"] - mu) / sd.replace(0, np.nan)\n",
    "    mask = (z.abs() > s).fillna(False)\n",
    "    return mask.reindex(series.index)\n",
    "\n",
    "def ticker_from_path(path):\n",
    "    base = os.path.basename(path)\n",
    "    return base.split(\"_cleaned\", 1)[0]\n",
    "\n",
    "def collect_train_test_pairs(data_dir, tickers=None):\n",
    "    train_paths = glob.glob(os.path.join(data_dir, \"*_cleaned_2008_2020.csv\"))\n",
    "    test_paths  = glob.glob(os.path.join(data_dir, \"*_cleaned_2020_onward.csv\"))\n",
    "    train_map = {ticker_from_path(p): p for p in train_paths}\n",
    "    test_map  = {ticker_from_path(p): p for p in test_paths}\n",
    "    pairs = {}\n",
    "    for tkr in sorted(set(train_map).intersection(test_map)):\n",
    "        if tickers and tkr not in tickers:\n",
    "            continue\n",
    "        pairs[tkr] = (train_map[tkr], test_map[tkr])\n",
    "    return pairs\n",
    "\n",
    "def plot_ticker(tkr, ret_train, ret_test, s, meth, freq_tag):\n",
    "    combined = pd.concat([ret_train, ret_test]).sort_index()\n",
    "    if meth == \"overall\":\n",
    "        mask = detect_outliers_overall(combined, s)\n",
    "        outlier_label = f\"outlier (|z|>{s:g}) overall\"\n",
    "    elif meth == \"seasonal\":\n",
    "        mask = detect_outliers_seasonal(combined, s)\n",
    "        outlier_label = f\"outlier (|z|>{s:g}) seasonal\"\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'overall' or 'seasonal'\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    if not ret_train.empty:\n",
    "        ax.plot(ret_train.index, ret_train.values, marker='.', linewidth=1.0, label=\"train 2008–2020\")\n",
    "    if not ret_test.empty:\n",
    "        ax.plot(ret_test.index, ret_test.values, marker='.', linewidth=1.0, label=\"test 2020–onward\")\n",
    "    if mask.any():\n",
    "        ax.scatter(combined.index[mask], combined[mask].values, s=80, zorder=5, label=outlier_label)\n",
    "    ax.axhline(0.0, linewidth=0.8)\n",
    "    ax.set_title(f\"{tkr}: {freq_tag} returns with outliers ({meth}, σ={s:g})\")\n",
    "    ax.set_xlabel(\"date\")\n",
    "    ax.set_ylabel(f\"{freq_tag} return\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "freqs = [(\"weekly\",\"W-FRI\"), (\"monthly\",\"ME\"), (\"yearly\",\"YE-DEC\")]\n",
    "\n",
    "pairs = collect_train_test_pairs(data_dir, tickers=tickers_to_plot)\n",
    "print(\"paired tickers:\", len(pairs))\n",
    "\n",
    "for tkr, (train_path, test_path) in sorted(pairs.items()):\n",
    "    df_tr = load_clean_csv(train_path)\n",
    "    df_te = load_clean_csv(test_path)\n",
    "    for freq_tag, rule in freqs:\n",
    "        ret_tr = returns_from_real_close(df_tr, rule)\n",
    "        ret_te = returns_from_real_close(df_te, rule)\n",
    "        if ret_tr.empty and ret_te.empty:\n",
    "            continue\n",
    "        plot_ticker(tkr, ret_tr, ret_te, sigma, method, freq_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# learn 2008–2020 month/week/year mean returns, predict 2020+ by matching calendar slot, and plot actual vs expected\n",
    "\n",
    "sigma = 3.0\n",
    "method = \"overall\"\n",
    "tickers_to_plot = None\n",
    "show_outliers = False\n",
    "\n",
    "def load_clean_csv(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "    except ValueError:\n",
    "        df = pd.read_csv(path, index_col=0, parse_dates=[0])\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df = df.sort_index()\n",
    "    if \"date\" in df.columns and df.index.name is None:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.set_index(\"date\")\n",
    "    return df\n",
    "\n",
    "def returns_from_real_close(df, rule):\n",
    "    if \"real_close\" not in df.columns:\n",
    "        return pd.Series(dtype=float)\n",
    "    close_p = df[\"real_close\"].resample(rule).last()\n",
    "    ret_p = close_p.pct_change().dropna()\n",
    "    return ret_p\n",
    "\n",
    "def detect_outliers_overall(series, s):\n",
    "    mu = series.mean()\n",
    "    sd = series.std()\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return pd.Series(False, index=series.index)\n",
    "    z = (series - mu) / sd\n",
    "    return z.abs() > s\n",
    "\n",
    "def detect_outliers_seasonal(series, s):\n",
    "    df_ = pd.DataFrame({\"ret\": series})\n",
    "    df_[\"month\"] = df_.index.month\n",
    "    stats = df_.groupby(\"month\")[\"ret\"].agg([\"mean\", \"std\"])\n",
    "    mu = df_[\"month\"].map(stats[\"mean\"])\n",
    "    sd = df_[\"month\"].map(stats[\"std\"])\n",
    "    z = (df_[\"ret\"] - mu) / sd.replace(0, np.nan)\n",
    "    mask = (z.abs() > s).fillna(False)\n",
    "    return mask.reindex(series.index)\n",
    "\n",
    "def ticker_from_path(path):\n",
    "    base = os.path.basename(path)\n",
    "    return base.split(\"_cleaned\", 1)[0]\n",
    "\n",
    "def collect_train_test_pairs(data_dir, tickers=None):\n",
    "    train_paths = glob.glob(os.path.join(data_dir, \"*_cleaned_2008_2020.csv\"))\n",
    "    test_paths  = glob.glob(os.path.join(data_dir, \"*_cleaned_2020_onward.csv\"))\n",
    "    train_map = {ticker_from_path(p): p for p in train_paths}\n",
    "    test_map  = {ticker_from_path(p): p for p in test_paths}\n",
    "    pairs = {}\n",
    "    for tkr in sorted(set(train_map).intersection(test_map)):\n",
    "        if tickers and tkr not in tickers:\n",
    "            continue\n",
    "        pairs[tkr] = (train_map[tkr], test_map[tkr])\n",
    "    return pairs\n",
    "\n",
    "def seasonal_profile_on_train(ret_train, freq_tag):\n",
    "    idx = ret_train.index\n",
    "    if freq_tag == \"monthly\":\n",
    "        key = idx.month\n",
    "        prof = pd.Series(ret_train.values, index=key).groupby(level=0).mean()\n",
    "        return prof  # index 1..12\n",
    "    elif freq_tag == \"weekly\":\n",
    "        # ISO week number (1..53)\n",
    "        week = idx.isocalendar().week.to_numpy()\n",
    "        prof = pd.Series(ret_train.values, index=week).groupby(level=0).mean()\n",
    "        return prof  # index 1..53 (some weeks may be missing)\n",
    "    elif freq_tag == \"yearly\":\n",
    "        # no within-year seasonality -> constant mean\n",
    "        return pd.Series({0: ret_train.mean()})\n",
    "    else:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "def predict_seasonal_on_test(ret_train, ret_test, freq_tag):\n",
    "    prof = seasonal_profile_on_train(ret_train, freq_tag)\n",
    "    if prof.empty:\n",
    "        return pd.Series(index=ret_test.index, dtype=float)\n",
    "\n",
    "    if freq_tag == \"monthly\":\n",
    "        keys = ret_test.index.month\n",
    "        yhat = pd.Series(index=ret_test.index, dtype=float)\n",
    "        for k in np.unique(keys):\n",
    "            if k in prof.index:\n",
    "                yhat[keys == k] = prof.loc[k]\n",
    "        return yhat\n",
    "    elif freq_tag == \"weekly\":\n",
    "        keys = ret_test.index.isocalendar().week.to_numpy()\n",
    "        yhat = pd.Series(index=ret_test.index, dtype=float)\n",
    "        for k in np.unique(keys):\n",
    "            if k in prof.index:\n",
    "                yhat[keys == k] = prof.loc[k]\n",
    "        return yhat\n",
    "    elif freq_tag == \"yearly\":\n",
    "        const = prof.iloc[0] if not prof.empty else np.nan\n",
    "        return pd.Series(const, index=ret_test.index)\n",
    "    else:\n",
    "        return pd.Series(index=ret_test.index, dtype=float)\n",
    "\n",
    "def plot_test_vs_pred(tkr, ret_train, ret_test, freq_tag, s, meth, show_outliers=False):\n",
    "    yhat = predict_seasonal_on_test(ret_train, ret_test, freq_tag)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    if not ret_test.empty:\n",
    "        ax.plot(ret_test.index, ret_test.values, marker='.', linewidth=1.0, label=\"actual 2020–onward\")\n",
    "    if not yhat.empty:\n",
    "        ax.plot(yhat.index, yhat.values, linewidth=2.0, label=\"predicted seasonal (fit on 2008–2020)\")\n",
    "\n",
    "    if show_outliers and not ret_test.empty:\n",
    "        if meth == \"overall\":\n",
    "            mask = detect_outliers_overall(ret_test, s)\n",
    "        else:\n",
    "            mask = detect_outliers_seasonal(ret_test, s)\n",
    "        if mask.any():\n",
    "            ax.scatter(ret_test.index[mask], ret_test[mask].values, s=80, zorder=5, label=f\"outlier (|z|>{s:g})\")\n",
    "\n",
    "    ax.axhline(0.0, linewidth=0.8)\n",
    "    ax.set_title(f\"{tkr}: {freq_tag} returns — seasonal prediction (train) vs actual (test)\")\n",
    "    ax.set_xlabel(\"date\")\n",
    "    ax.set_ylabel(f\"{freq_tag} return\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    if not ret_test.empty:\n",
    "        ax.set_xlim(ret_test.index.min(), ret_test.index.max())\n",
    "    plt.show()\n",
    "\n",
    "freqs = [(\"weekly\",\"W-FRI\"), (\"monthly\",\"ME\"), (\"yearly\",\"YE-DEC\")]\n",
    "\n",
    "pairs = collect_train_test_pairs(data_dir, tickers=tickers_to_plot)\n",
    "print(\"paired tickers:\", len(pairs))\n",
    "\n",
    "for tkr, (train_path, test_path) in sorted(pairs.items()):\n",
    "    df_tr = load_clean_csv(train_path)\n",
    "    df_te = load_clean_csv(test_path)\n",
    "    for freq_tag, rule in freqs:\n",
    "        ret_tr = returns_from_real_close(df_tr, rule)\n",
    "        ret_te = returns_from_real_close(df_te, rule)\n",
    "        if ret_te.empty:\n",
    "            continue\n",
    "        plot_test_vs_pred(tkr, ret_tr, ret_te, freq_tag, sigma, method, show_outliers=show_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fit 2008–2020 returns with ols (time trend + seasonal dummies [+ volume z-scored]), predict on 2020+ timestamps, plot actual vs predicted\n",
    "\n",
    "sigma = 3.0\n",
    "method = \"overall\"\n",
    "tickers_to_plot = None\n",
    "\n",
    "def load_clean_csv(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "    except ValueError:\n",
    "        df = pd.read_csv(path, index_col=0, parse_dates=[0])\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df = df.sort_index()\n",
    "    if \"date\" in df.columns and df.index.name is None:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.set_index(\"date\")\n",
    "    return df\n",
    "\n",
    "def resample_returns_and_volume(df, rule):\n",
    "    has_vol = \"volume\" in df.columns\n",
    "    close_p = df[\"real_close\"].resample(rule).last()\n",
    "    ret_p = close_p.pct_change()\n",
    "    if has_vol:\n",
    "        vol_p = df[\"volume\"].resample(rule).sum()\n",
    "        out = pd.DataFrame({\"ret\": ret_p, \"volume\": vol_p})\n",
    "    else:\n",
    "        out = pd.DataFrame({\"ret\": ret_p})\n",
    "    return out.dropna()\n",
    "\n",
    "def ticker_from_path(path):\n",
    "    base = os.path.basename(path)\n",
    "    return base.split(\"_cleaned\", 1)[0]\n",
    "\n",
    "def collect_train_test_pairs(data_dir, tickers=None):\n",
    "    train_paths = glob.glob(os.path.join(data_dir, \"*_cleaned_2008_2020.csv\"))\n",
    "    test_paths  = glob.glob(os.path.join(data_dir, \"*_cleaned_2020_onward.csv\"))\n",
    "    train_map = {ticker_from_path(p): p for p in train_paths}\n",
    "    test_map  = {ticker_from_path(p): p for p in test_paths}\n",
    "    pairs = {}\n",
    "    for tkr in sorted(set(train_map).intersection(test_map)):\n",
    "        if tickers and tkr not in tickers:\n",
    "            continue\n",
    "        pairs[tkr] = (train_map[tkr], test_map[tkr])\n",
    "    return pairs\n",
    "\n",
    "def make_design(df_train, df_test, freq_tag):\n",
    "    df_tr = df_train.copy()\n",
    "    df_te = df_test.copy()\n",
    "    df_tr[\"t\"] = np.arange(len(df_tr), dtype=float)\n",
    "    df_te[\"t\"] = np.arange(len(df_tr), len(df_tr)+len(df_te), dtype=float)\n",
    "\n",
    "    if \"volume\" in df_tr.columns and \"volume\" in df_te.columns:\n",
    "        mu = df_tr[\"volume\"].mean()\n",
    "        sd = df_tr[\"volume\"].std()\n",
    "        if sd == 0 or np.isnan(sd):\n",
    "            df_tr[\"vol_z\"] = 0.0\n",
    "            df_te[\"vol_z\"] = 0.0\n",
    "        else:\n",
    "            df_tr[\"vol_z\"] = (df_tr[\"volume\"] - mu) / sd\n",
    "            df_te[\"vol_z\"] = (df_te[\"volume\"] - mu) / sd\n",
    "        use_vol = True\n",
    "    else:\n",
    "        use_vol = False\n",
    "\n",
    "    if freq_tag == \"monthly\":\n",
    "        df_tr[\"slot\"] = df_tr.index.month.astype(int)\n",
    "        df_te[\"slot\"] = df_te.index.month.astype(int)\n",
    "        d_tr = pd.get_dummies(df_tr[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"m\")\n",
    "        d_te = pd.get_dummies(df_te[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"m\")\n",
    "        d_tr, d_te = d_tr.align(d_te, join=\"outer\", axis=1, fill_value=0)\n",
    "    elif freq_tag == \"weekly\":\n",
    "        df_tr[\"slot\"] = df_tr.index.isocalendar().week.astype(int).to_numpy()\n",
    "        df_te[\"slot\"] = df_te.index.isocalendar().week.astype(int).to_numpy()\n",
    "        d_tr = pd.get_dummies(df_tr[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"w\")\n",
    "        d_te = pd.get_dummies(df_te[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"w\")\n",
    "        d_tr, d_te = d_tr.align(d_te, join=\"outer\", axis=1, fill_value=0)\n",
    "    else:\n",
    "        d_tr = pd.DataFrame(index=df_tr.index)\n",
    "        d_te = pd.DataFrame(index=df_te.index)\n",
    "\n",
    "    x_tr_cols = [\"t\"] + ([\"vol_z\"] if use_vol else []) + list(d_tr.columns)\n",
    "    x_te_cols = [\"t\"] + ([\"vol_z\"] if use_vol else []) + list(d_te.columns)\n",
    "\n",
    "    X_tr = sm.add_constant(pd.concat([df_tr[[\"t\"] + ([\"vol_z\"] if use_vol else [])], d_tr], axis=1).astype(float), has_constant=\"add\")\n",
    "    X_te = sm.add_constant(pd.concat([df_te[[\"t\"] + ([\"vol_z\"] if use_vol else [])], d_te], axis=1).astype(float), has_constant=\"add\")\n",
    "    y_tr = df_tr[\"ret\"].astype(float)\n",
    "\n",
    "    return X_tr, y_tr, X_te\n",
    "\n",
    "def fit_predict_train_ols(X_tr, y_tr, X_te):\n",
    "    ok = y_tr.notna()\n",
    "    X = X_tr.loc[ok]\n",
    "    y = y_tr.loc[ok]\n",
    "    if len(y) < (X.shape[1] + 1):\n",
    "        return pd.Series(index=X_te.index, dtype=float), None\n",
    "    res = sm.OLS(y, X).fit()\n",
    "    yhat_te = pd.Series(res.predict(X_te), index=X_te.index)\n",
    "    return yhat_te, res\n",
    "\n",
    "def plot_test_actual_vs_pred(tkr, freq_tag, ret_test, yhat_te, res=None):\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    ax.plot(ret_test.index, ret_test.values, marker='.', linewidth=1.0, label=\"actual 2020–onward\")\n",
    "    ax.plot(yhat_te.index, yhat_te.values, linewidth=2.0, label=\"predicted (train OLS)\")\n",
    "    ax.axhline(0.0, linewidth=0.8)\n",
    "    ax.set_title(f\"{tkr}: {freq_tag} returns — OLS train(2008–2020) → predict(2020+)\")\n",
    "    ax.set_xlabel(\"date\")\n",
    "    ax.set_ylabel(f\"{freq_tag} return\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_xlim(ret_test.index.min(), ret_test.index.max())\n",
    "    plt.show()\n",
    "\n",
    "freqs = [(\"weekly\",\"W-FRI\"), (\"monthly\",\"ME\"), (\"yearly\",\"YE-DEC\")]\n",
    "\n",
    "pairs = collect_train_test_pairs(data_dir, tickers=tickers_to_plot)\n",
    "print(\"paired tickers:\", len(pairs))\n",
    "\n",
    "for tkr, (train_path, test_path) in pairs.items():\n",
    "    df_tr_raw = load_clean_csv(train_path)\n",
    "    df_te_raw = load_clean_csv(test_path)\n",
    "    for freq_tag, rule in freqs:\n",
    "        if \"real_close\" not in df_tr_raw.columns or \"real_close\" not in df_te_raw.columns:\n",
    "            continue\n",
    "        tr = resample_returns_and_volume(df_tr_raw, rule)\n",
    "        te = resample_returns_and_volume(df_te_raw, rule)\n",
    "        if te.empty or tr.empty:\n",
    "            continue\n",
    "        X_tr, y_tr, X_te = make_design(tr, te, freq_tag)\n",
    "        yhat_te, res = fit_predict_train_ols(X_tr, y_tr, X_te)\n",
    "        if yhat_te.empty:\n",
    "            continue\n",
    "        plot_test_actual_vs_pred(tkr, freq_tag, te[\"ret\"], yhat_te, res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit 2008–2020 returns with ols (centered time trend + seasonal dummies [+ volume z-scored]), drop ±3σ train outliers, predict 2020+ and plot actual vs predicted\n",
    "\n",
    "sigma = 3.0\n",
    "tickers_to_plot = None\n",
    "\n",
    "def load_clean_csv(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "    except ValueError:\n",
    "        df = pd.read_csv(path, index_col=0, parse_dates=[0])\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df = df.sort_index()\n",
    "    if \"date\" in df.columns and df.index.name is None:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.set_index(\"date\")\n",
    "    return df\n",
    "\n",
    "def safe_pct_change(s):\n",
    "    r = s.pct_change()\n",
    "    return r.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def flag_outliers_3sigma(series):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    mu = s.mean()\n",
    "    sd = s.std(ddof=1)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        z = pd.Series(np.nan, index=s.index)\n",
    "        mask = pd.Series(False, index=s.index)\n",
    "        return mu, sd, z, mask\n",
    "    z = (s - mu) / sd\n",
    "    mask = z.abs() > 3\n",
    "    return mu, sd, z, mask\n",
    "\n",
    "def ticker_from_path(path):\n",
    "    base = os.path.basename(path)\n",
    "    return base.split(\"_cleaned\", 1)[0]\n",
    "\n",
    "def collect_train_test_pairs(data_dir, tickers=None):\n",
    "    train_paths = glob.glob(os.path.join(data_dir, \"*_cleaned_2008_2020.csv\"))\n",
    "    test_paths  = glob.glob(os.path.join(data_dir, \"*_cleaned_2020_onward.csv\"))\n",
    "    train_map = {ticker_from_path(p): p for p in train_paths}\n",
    "    test_map  = {ticker_from_path(p): p for p in test_paths}\n",
    "    pairs = {}\n",
    "    for tkr in sorted(set(train_map).intersection(test_map)):\n",
    "        if tickers and tkr not in tickers:\n",
    "            continue\n",
    "        pairs[tkr] = (train_map[tkr], test_map[tkr])\n",
    "    return pairs\n",
    "\n",
    "def resample_returns_and_volume(df, rule):\n",
    "    close_p = df[\"real_close\"].resample(rule).last()\n",
    "    ret_p   = safe_pct_change(close_p)\n",
    "    out = pd.DataFrame({\"ret\": ret_p})\n",
    "    if \"volume\" in df.columns:\n",
    "        out[\"volume\"] = df[\"volume\"].resample(rule).sum()\n",
    "    return out.dropna()\n",
    "\n",
    "def make_design(df_train, df_test, freq_tag):\n",
    "    df_tr = df_train.copy()\n",
    "    df_te = df_test.copy()\n",
    "\n",
    "    df_tr[\"t\"] = np.arange(len(df_tr), dtype=float)\n",
    "    df_te[\"t\"] = np.arange(len(df_tr), len(df_tr)+len(df_te), dtype=float)\n",
    "    # center t on train so const = mean-period level (like your MLR block)\n",
    "    t_mu = df_tr[\"t\"].mean()\n",
    "    df_tr[\"t\"] -= t_mu\n",
    "    df_te[\"t\"] -= t_mu\n",
    "\n",
    "    if \"volume\" in df_tr.columns and \"volume\" in df_te.columns:\n",
    "        mu = df_tr[\"volume\"].mean()\n",
    "        sd = df_tr[\"volume\"].std(ddof=1)\n",
    "        if sd == 0 or np.isnan(sd):\n",
    "            df_tr[\"vol_z\"] = 0.0\n",
    "            df_te[\"vol_z\"] = 0.0\n",
    "        else:\n",
    "            df_tr[\"vol_z\"] = (df_tr[\"volume\"] - mu) / sd\n",
    "            df_te[\"vol_z\"] = (df_te[\"volume\"] - mu) / sd\n",
    "        use_vol = True\n",
    "    else:\n",
    "        use_vol = False\n",
    "\n",
    "    if freq_tag == \"monthly\":\n",
    "        df_tr[\"slot\"] = df_tr.index.month.astype(int)\n",
    "        df_te[\"slot\"] = df_te.index.month.astype(int)\n",
    "        d_tr = pd.get_dummies(df_tr[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"m\")\n",
    "        d_te = pd.get_dummies(df_te[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"m\")\n",
    "        d_tr, d_te = d_tr.align(d_te, join=\"outer\", axis=1, fill_value=0)\n",
    "    elif freq_tag == \"weekly\":\n",
    "        df_tr[\"slot\"] = df_tr.index.isocalendar().week.astype(int).to_numpy()\n",
    "        df_te[\"slot\"] = df_te.index.isocalendar().week.astype(int).to_numpy()\n",
    "        d_tr = pd.get_dummies(df_tr[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"w\")\n",
    "        d_te = pd.get_dummies(df_te[\"slot\"].astype(\"category\"), drop_first=True, prefix=\"w\")\n",
    "        d_tr, d_te = d_tr.align(d_te, join=\"outer\", axis=1, fill_value=0)\n",
    "    else:\n",
    "        d_tr = pd.DataFrame(index=df_tr.index)\n",
    "        d_te = pd.DataFrame(index=df_te.index)\n",
    "\n",
    "    X_tr = pd.concat([df_tr[[\"t\"] + ([\"vol_z\"] if use_vol else [])], d_tr], axis=1).astype(float)\n",
    "    X_te = pd.concat([df_te[[\"t\"] + ([\"vol_z\"] if use_vol else [])], d_te], axis=1).astype(float)\n",
    "    X_tr = sm.add_constant(X_tr, has_constant=\"add\")\n",
    "    X_te = sm.add_constant(X_te, has_constant=\"add\")\n",
    "    y_tr = df_tr[\"ret\"].astype(float)\n",
    "\n",
    "    return X_tr, y_tr, X_te\n",
    "\n",
    "def fit_predict_ols_train_only(X_tr, y_tr, X_te):\n",
    "    mu, sd, z, mask = flag_outliers_3sigma(y_tr)    # drop ±3σ train outliers (your rule)\n",
    "    ok = y_tr.notna() & (~mask)\n",
    "    X = X_tr.loc[ok]\n",
    "    y = y_tr.loc[ok]\n",
    "    if len(y) <= X.shape[1] + 1:\n",
    "        return pd.Series(index=X_te.index, dtype=float), None\n",
    "    res = sm.OLS(y, X).fit()\n",
    "    yhat = pd.Series(res.predict(X_te), index=X_te.index)\n",
    "    return yhat, res\n",
    "\n",
    "def plot_test_overlay(tkr, freq_tag, ret_test, yhat_te):\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    ax.plot(ret_test.index, ret_test.values, marker='.', linewidth=1.0, label=\"actual 2020–onward\")\n",
    "    ax.plot(yhat_te.index, yhat_te.values, linewidth=2.0, label=\"predicted OLS (train 2008–2020)\")\n",
    "    ax.axhline(0.0, linewidth=0.8)\n",
    "    ax.set_title(f\"{tkr}: {freq_tag} returns — train OLS vs test actual\")\n",
    "    ax.set_xlabel(\"date\")\n",
    "    ax.set_ylabel(f\"{freq_tag} return\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_xlim(ret_test.index.min(), ret_test.index.max())\n",
    "    plt.show()\n",
    "\n",
    "freqs = [(\"weekly\",\"W-FRI\"), (\"monthly\",\"ME\"), (\"yearly\",\"YE-DEC\")]\n",
    "\n",
    "pairs = collect_train_test_pairs(data_dir, tickers=tickers_to_plot)\n",
    "print(\"paired tickers:\", len(pairs))\n",
    "\n",
    "for tkr, (train_path, test_path) in pairs.items():\n",
    "    df_tr = load_clean_csv(train_path)\n",
    "    df_te = load_clean_csv(test_path)\n",
    "    if \"real_close\" not in df_tr.columns or \"real_close\" not in df_te.columns:\n",
    "        continue\n",
    "    for freq_tag, rule in freqs:\n",
    "        tr = resample_returns_and_volume(df_tr, rule)\n",
    "        te = resample_returns_and_volume(df_te, rule)\n",
    "        if tr.empty or te.empty:\n",
    "            continue\n",
    "        X_tr, y_tr, X_te = make_design(tr, te, freq_tag)\n",
    "        yhat_te, res = fit_predict_ols_train_only(X_tr, y_tr, X_te)\n",
    "        if yhat_te.empty:\n",
    "            continue\n",
    "        plot_test_overlay(tkr, freq_tag, te[\"ret\"], yhat_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
